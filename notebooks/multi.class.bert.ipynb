{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1024 09:09:43.786980 140208979011328 file_utils.py:39] PyTorch version 1.0.1.post2 available.\n",
      "I1024 09:09:44.051237 140208979011328 modeling_xlnet.py:194] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "import os\n",
    "import random\n",
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer)\n",
    "from transformers import AdamW, WarmupLinearSchedule\n",
    "\n",
    "MODEL_CLASSES = { 'bert': (BertConfig, BertForSequenceClassification, BertTokenizer) }\n",
    "import logging\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    n_gpu=1,\n",
    "    seed=1337,\n",
    "    train_batch_size=8,\n",
    "    per_gpu_train_batch_size=8,\n",
    "    per_gpu_eval_batch_size=8,\n",
    "    local_rank=-1,\n",
    "    max_seq_length=128,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    max_grad_norm=1.0,\n",
    "    num_train_epochs=3.0,\n",
    "    max_steps=-1,\n",
    "    warmup_steps=0,\n",
    "    model_type='bert',\n",
    "    data_dir='/floyd/home/data',\n",
    "    output_dir='/floyd/home/model/bert-model',\n",
    "    train_filepath='',\n",
    "    valid_filepath='',\n",
    "    test_filepath='',\n",
    "    config_name='bert-base-uncased',\n",
    "    tokenizer_name='bert-base-uncased',\n",
    "    do_lower_case=True,\n",
    "    cuda=True,\n",
    ")\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "args.train_filepath = os.path.join(args.data_dir, 'train.csv')\n",
    "args.valid_filepath=os.path.join(args.data_dir, 'benchmark.csv')\n",
    "args.test_filepath=os.path.join(args.data_dir, 'test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparation: utility class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"\n",
    "    A single training/test example for simple sequence classification.\n",
    "\n",
    "    Args:\n",
    "        guid: Unique id for the example.\n",
    "        text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "        text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "        label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        self.guid   = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label  = label\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"\n",
    "    A single set of features of data.\n",
    "\n",
    "    Args:\n",
    "        input_ids: Indices of input sequence tokens in the vocabulary.\n",
    "        attention_mask: Mask to avoid performing attention on padding token indices.\n",
    "            Mask values selected in ``[0, 1]``:\n",
    "            Usually  ``1`` for tokens that are NOT MASKED, ``0`` for MASKED (padded) tokens.\n",
    "        token_type_ids: Segment token indices to indicate first and second portions of the inputs.\n",
    "        label: Label corresponding to the input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, attention_mask, token_type_ids, label):\n",
    "        self.input_ids      = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.label          = label\n",
    "\n",
    "\n",
    "class DataProcessor(object):\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_train_examples(self):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def get_test_examples(self):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the MultiNLI data set (GLUE version).\"\"\"\n",
    "\n",
    "    def __init__(self, train_filepath, dev_filepath, test_filepath):\n",
    "        self.train_filepath = train_filepath\n",
    "        self.dev_filepath   = dev_filepath\n",
    "        self.test_filepath  = test_filepath\n",
    "\n",
    "    def get_train_examples(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        df            = self._get_dataframe(self.train_filepath)\n",
    "        return self._get_examples(df)\n",
    "\n",
    "    def get_dev_examples(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        df            = self._get_dataframe(self.dev_filepath)\n",
    "        return self._get_examples(df)\n",
    "    \n",
    "    def get_test_examples(self):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        df            = self._get_dataframe(self.test_filepath)\n",
    "        return self._get_examples(df)\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        df            = pd.read_csv(self.train_filepath)\n",
    "        self.labels   = list(df.labels.unique())\n",
    "        return self.labels\n",
    "    \n",
    "    def _get_dataframe(self, filepath):\n",
    "        df            = pd.read_csv(filepath)\n",
    "        return df\n",
    "\n",
    "    def _get_examples(self, df):\n",
    "        examples = []\n",
    "        for index, row in df.iterrows():\n",
    "            examples.append(InputExample(guid=str(uuid.uuid4()), text_a=row['texts'], text_b=None, label=row['labels']))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_examples_to_features(examples, tokenizer,\n",
    "                                      max_length=512,\n",
    "                                      task=None,\n",
    "                                      label_list=None,\n",
    "                                      output_mode=None, \n",
    "                                      pad_on_left=False,\n",
    "                                      pad_token=0,\n",
    "                                      pad_token_segment_id=0,\n",
    "                                      mask_padding_with_zero=True):\n",
    "    \"\"\"\n",
    "    Loads a data file into a list of ``InputFeatures``\n",
    "\n",
    "    Args:\n",
    "        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.\n",
    "        tokenizer: Instance of a tokenizer that will tokenize the examples\n",
    "        max_length: Maximum example length\n",
    "        task: GLUE task\n",
    "        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n",
    "        output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n",
    "        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n",
    "        pad_token: Padding token\n",
    "        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n",
    "        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n",
    "            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n",
    "            actual values)\n",
    "\n",
    "    Returns:\n",
    "        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n",
    "        containing the task-specific features. If the input is a list of ``InputExamples``, will return\n",
    "        a list of task-specific ``InputFeatures`` which can be fed to the model.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if task is not None:\n",
    "        processor = glue_processors[task]()\n",
    "        if label_list is None:\n",
    "            label_list = processor.get_labels()\n",
    "            logger.info(\"Using label list %s for task %s\" % (label_list, task))\n",
    "        if output_mode is None:\n",
    "            output_mode = glue_output_modes[task]\n",
    "            logger.info(\"Using output mode %s for task %s\" % (output_mode, task))\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            logger.info(\"Writing example %d\" % (ex_index))\n",
    "\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            example.text_a,\n",
    "            example.text_b,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        input_ids, token_type_ids = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_length - len(input_ids)\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask\n",
    "            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids\n",
    "        else:\n",
    "            input_ids = input_ids + ([pad_token] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_ids), max_length)\n",
    "        assert len(attention_mask) == max_length, \"Error with input length {} vs {}\".format(len(attention_mask), max_length)\n",
    "        assert len(token_type_ids) == max_length, \"Error with input length {} vs {}\".format(len(token_type_ids), max_length)\n",
    "\n",
    "        label = label_map[example.label]\n",
    "\n",
    "        if ex_index < 5:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"guid: %s\" % (example.guid))\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"attention_mask: %s\" % \" \".join([str(x) for x in attention_mask]))\n",
    "            logger.info(\"token_type_ids: %s\" % \" \".join([str(x) for x in token_type_ids]))\n",
    "            logger.info(\"label: %s (id = %d)\" % (example.label, label))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              attention_mask=attention_mask,\n",
    "                              token_type_ids=token_type_ids,\n",
    "                              label=label))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples_dataset(examples, labels, tokenzier):\n",
    "    features = convert_examples_to_features(examples,\n",
    "                                            tokenizer,\n",
    "                                            label_list=labels,\n",
    "                                            max_length=args.max_seq_length,\n",
    "                                            pad_on_left=False,\n",
    "                                            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "                                            pad_token_segment_id=0,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids       = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_attention_mask  = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_token_type_ids  = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    all_labels          = torch.tensor([f.label for f in features], dtype=torch.long)\n",
    "    \n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start of program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor       = MultiClassProcessor(args.train_filepath, args.valid_filepath, args.test_filepath)\n",
    "label_list      = processor.get_labels()\n",
    "train_examples  = processor.get_train_examples()\n",
    "eval_examples   = processor.get_dev_examples()\n",
    "test_examples   = processor.get_test_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1024 09:09:56.824881 140208979011328 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpfcg5f7bv\n",
      "100%|██████████| 313/313 [00:00<00:00, 136851.57B/s]\n",
      "I1024 09:09:57.141306 140208979011328 file_utils.py:309] copying /tmp/tmpfcg5f7bv to cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1024 09:09:57.142598 140208979011328 file_utils.py:313] creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1024 09:09:57.144853 140208979011328 file_utils.py:322] removing temp file /tmp/tmpfcg5f7bv\n",
      "I1024 09:09:57.148451 140208979011328 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "I1024 09:09:57.151919 140208979011328 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 97,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1024 09:09:57.501047 140208979011328 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpj4z94l_i\n",
      "100%|██████████| 231508/231508 [00:00<00:00, 590399.83B/s]\n",
      "I1024 09:09:58.076127 140208979011328 file_utils.py:309] copying /tmp/tmpj4z94l_i to cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I1024 09:09:58.078661 140208979011328 file_utils.py:313] creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I1024 09:09:58.079739 140208979011328 file_utils.py:322] removing temp file /tmp/tmpj4z94l_i\n",
      "I1024 09:09:58.080581 140208979011328 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I1024 09:09:58.445038 140208979011328 file_utils.py:296] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpj0qtavt9\n",
      "100%|██████████| 440473133/440473133 [00:23<00:00, 18824449.40B/s]\n",
      "I1024 09:10:22.189886 140208979011328 file_utils.py:309] copying /tmp/tmpj0qtavt9 to cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I1024 09:10:22.693217 140208979011328 file_utils.py:313] creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I1024 09:10:22.694705 140208979011328 file_utils.py:322] removing temp file /tmp/tmpj0qtavt9\n",
      "I1024 09:10:22.782588 140208979011328 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "I1024 09:10:26.977650 140208979011328 modeling_utils.py:405] Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1024 09:10:26.978905 140208979011328 modeling_utils.py:408] Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "config       = config_class.from_pretrained(args.config_name, num_labels=len(label_list))\n",
    "tokenizer    = tokenizer_class.from_pretrained(args.tokenizer_name, do_lower_case=args.do_lower_case)\n",
    "model        = model_class.from_pretrained(args.config_name, config=config).to(args.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training and evaluation helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "def compute_metrics(task_name, preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return {\"acc\": simple_accuracy(preds, labels)}\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_dataset, model, tokenizer):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    args.train_batch_size   = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "    train_sampler           = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
    "    train_dataloader        = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "    t_total                 = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])\n",
    "    set_seed(args)  # Added here for reproductibility (even between python 2 and 3)\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(args.device) for t in batch)\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[3]}\n",
    "            if args.model_type != 'distilbert':\n",
    "                inputs['token_type_ids'] = batch[2] if args.model_type in ['bert', 'xlnet'] else None  # XLM, DistilBERT and RoBERTa don't use segment_ids\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
    "\n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean() # mean() to average on multi-gpu parallel training\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "                \n",
    "                if global_step % 100 == 0:\n",
    "                    output_dir = os.path.join(args.output_dir, 'checkpoint-{}'.format(global_step))\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "                    model_to_save.save_pretrained(output_dir)\n",
    "                    tokenizer.save_pretrained(args.output_dir)\n",
    "                    \n",
    "                    torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "                    \n",
    "    # save \n",
    "    return global_step, tr_loss / global_step\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(args, eval_dataset, model, tokenizer):\n",
    "    results = {}\n",
    "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(eval_dataset) if args.local_rank == -1 else DistributedSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[3]}\n",
    "            if args.model_type != 'distilbert':\n",
    "                inputs['token_type_ids'] = batch[2] if args.model_type in ['bert', 'xlnet'] else None  # XLM, DistilBERT and RoBERTa don't use segment_ids\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        \n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "            \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    result = compute_metrics(\"eval_task\", preds, out_label_ids)\n",
    "    results.update(result)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1023 02:55:11.695903 139701840725760 <ipython-input-7-9a70535d1c4a>:49] Writing example 0\n",
      "I1023 02:55:11.697530 139701840725760 <ipython-input-7-9a70535d1c4a>:81] *** Example ***\n",
      "I1023 02:55:11.698590 139701840725760 <ipython-input-7-9a70535d1c4a>:82] guid: 9be98940-f718-4cae-ab11-34bccc927a42\n",
      "I1023 02:55:11.699678 139701840725760 <ipython-input-7-9a70535d1c4a>:83] input_ids: 101 4863 2033 2054 2000 25856 2515 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.700604 139701840725760 <ipython-input-7-9a70535d1c4a>:84] attention_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.701569 139701840725760 <ipython-input-7-9a70535d1c4a>:85] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.702481 139701840725760 <ipython-input-7-9a70535d1c4a>:86] label: ask_faq_what_totp (id = 0)\n",
      "I1023 02:55:11.704059 139701840725760 <ipython-input-7-9a70535d1c4a>:81] *** Example ***\n",
      "I1023 02:55:11.704919 139701840725760 <ipython-input-7-9a70535d1c4a>:82] guid: 3dcbb302-63f5-4c18-be0f-74d4e9d3dedb\n",
      "I1023 02:55:11.705850 139701840725760 <ipython-input-7-9a70535d1c4a>:83] input_ids: 101 1045 2215 2000 4553 2242 2055 2000 25856 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.706880 139701840725760 <ipython-input-7-9a70535d1c4a>:84] attention_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.707777 139701840725760 <ipython-input-7-9a70535d1c4a>:85] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.708680 139701840725760 <ipython-input-7-9a70535d1c4a>:86] label: ask_faq_what_totp (id = 0)\n",
      "I1023 02:55:11.709832 139701840725760 <ipython-input-7-9a70535d1c4a>:81] *** Example ***\n",
      "I1023 02:55:11.710790 139701840725760 <ipython-input-7-9a70535d1c4a>:82] guid: 452e74b0-b356-4fbe-9cec-0ba4dad4e0e3\n",
      "I1023 02:55:11.711637 139701840725760 <ipython-input-7-9a70535d1c4a>:83] input_ids: 101 2054 2003 2000 25856 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.712785 139701840725760 <ipython-input-7-9a70535d1c4a>:84] attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.713682 139701840725760 <ipython-input-7-9a70535d1c4a>:85] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.714600 139701840725760 <ipython-input-7-9a70535d1c4a>:86] label: ask_faq_what_totp (id = 0)\n",
      "I1023 02:55:11.716064 139701840725760 <ipython-input-7-9a70535d1c4a>:81] *** Example ***\n",
      "I1023 02:55:11.717065 139701840725760 <ipython-input-7-9a70535d1c4a>:82] guid: ddc952bb-8a4e-4cc9-b210-eee3f747f768\n",
      "I1023 02:55:11.717971 139701840725760 <ipython-input-7-9a70535d1c4a>:83] input_ids: 101 2507 2033 2062 2592 2055 2000 25856 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.718965 139701840725760 <ipython-input-7-9a70535d1c4a>:84] attention_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.719961 139701840725760 <ipython-input-7-9a70535d1c4a>:85] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.720782 139701840725760 <ipython-input-7-9a70535d1c4a>:86] label: ask_faq_what_totp (id = 0)\n",
      "I1023 02:55:11.722499 139701840725760 <ipython-input-7-9a70535d1c4a>:81] *** Example ***\n",
      "I1023 02:55:11.723380 139701840725760 <ipython-input-7-9a70535d1c4a>:82] guid: 6669873c-b7af-4297-bad8-21868ae53810\n",
      "I1023 02:55:11.724305 139701840725760 <ipython-input-7-9a70535d1c4a>:83] input_ids: 101 1045 2215 2000 2113 2054 2000 25856 2515 2008 3475 1005 1056 3154 2000 2033 2664 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.725239 139701840725760 <ipython-input-7-9a70535d1c4a>:84] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.726252 139701840725760 <ipython-input-7-9a70535d1c4a>:85] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1023 02:55:11.727350 139701840725760 <ipython-input-7-9a70535d1c4a>:86] label: ask_faq_what_totp (id = 0)\n",
      "I1023 02:55:12.930766 139701840725760 <ipython-input-12-7408f09bfb68>:18] ***** Running training *****\n",
      "I1023 02:55:12.931915 139701840725760 <ipython-input-12-7408f09bfb68>:19]   Num examples = 3575\n",
      "I1023 02:55:12.933352 139701840725760 <ipython-input-12-7408f09bfb68>:20]   Num Epochs = 3\n",
      "I1023 02:55:12.934969 139701840725760 <ipython-input-12-7408f09bfb68>:21]   Instantaneous batch size per GPU = 8\n",
      "I1023 02:55:12.935910 139701840725760 <ipython-input-12-7408f09bfb68>:22]   Gradient Accumulation steps = 1\n",
      "I1023 02:55:12.936787 139701840725760 <ipython-input-12-7408f09bfb68>:23]   Total optimization steps = 1341\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/447 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/447 [00:01<09:47,  1.32s/it]\u001b[A\n",
      "Iteration:   0%|          | 2/447 [00:01<07:48,  1.05s/it]\u001b[A\n",
      "Iteration:   1%|          | 3/447 [00:02<06:25,  1.15it/s]\u001b[A\n",
      "Iteration:   1%|          | 4/447 [00:02<05:27,  1.35it/s]\u001b[A\n",
      "Iteration:   1%|          | 5/447 [00:03<04:46,  1.54it/s]\u001b[A\n",
      "Iteration:   1%|▏         | 6/447 [00:03<04:17,  1.71it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 7/447 [00:03<03:57,  1.85it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 8/447 [00:04<03:43,  1.96it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 9/447 [00:04<03:33,  2.05it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 10/447 [00:05<03:27,  2.11it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 11/447 [00:05<03:21,  2.16it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 12/447 [00:06<03:17,  2.20it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 13/447 [00:06<03:15,  2.22it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 14/447 [00:07<03:13,  2.24it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 15/447 [00:07<03:11,  2.25it/s]\u001b[A\n",
      "Iteration:   4%|▎         | 16/447 [00:07<03:10,  2.26it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 17/447 [00:08<03:09,  2.27it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 18/447 [00:08<03:08,  2.28it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 19/447 [00:09<03:07,  2.28it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 20/447 [00:09<03:07,  2.28it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 21/447 [00:10<03:06,  2.28it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 22/447 [00:10<03:06,  2.28it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 23/447 [00:10<03:05,  2.29it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 24/447 [00:11<03:05,  2.28it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 25/447 [00:11<03:04,  2.28it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 26/447 [00:12<03:04,  2.29it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 27/447 [00:12<03:04,  2.28it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 28/447 [00:13<03:03,  2.28it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 29/447 [00:13<03:03,  2.28it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 30/447 [00:14<03:02,  2.28it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 31/447 [00:14<03:02,  2.28it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 32/447 [00:14<03:01,  2.28it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 33/447 [00:15<03:02,  2.27it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 34/447 [00:15<03:01,  2.28it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 35/447 [00:16<03:01,  2.27it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 36/447 [00:16<03:00,  2.28it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 37/447 [00:17<02:59,  2.28it/s]\u001b[A\n",
      "Iteration:   9%|▊         | 38/447 [00:17<02:59,  2.28it/s]\u001b[A\n",
      "Iteration:   9%|▊         | 39/447 [00:17<02:58,  2.28it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 40/447 [00:18<02:58,  2.28it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 41/447 [00:18<02:57,  2.28it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 42/447 [00:19<02:57,  2.28it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 43/447 [00:19<02:57,  2.28it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 44/447 [00:20<02:57,  2.28it/s]\u001b[A\n",
      "Iteration:  10%|█         | 45/447 [00:20<02:56,  2.28it/s]\u001b[A\n",
      "Iteration:  10%|█         | 46/447 [00:21<02:56,  2.28it/s]\u001b[A\n",
      "Iteration:  11%|█         | 47/447 [00:21<02:55,  2.28it/s]\u001b[A\n",
      "Iteration:  11%|█         | 48/447 [00:21<02:54,  2.28it/s]\u001b[A\n",
      "Iteration:  11%|█         | 49/447 [00:22<02:54,  2.28it/s]\u001b[A\n",
      "Iteration:  11%|█         | 50/447 [00:22<02:53,  2.29it/s]\u001b[A\n",
      "Iteration:  11%|█▏        | 51/447 [00:23<02:53,  2.28it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 52/447 [00:23<02:53,  2.28it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 53/447 [00:24<02:52,  2.28it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 54/447 [00:24<02:52,  2.28it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 55/447 [00:24<02:51,  2.28it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 56/447 [00:25<02:51,  2.27it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 57/447 [00:25<02:51,  2.27it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 58/447 [00:26<02:50,  2.28it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 59/447 [00:26<02:50,  2.28it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 60/447 [00:27<02:49,  2.28it/s]\u001b[A\n",
      "Iteration:  14%|█▎        | 61/447 [00:27<02:49,  2.27it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 62/447 [00:28<02:49,  2.27it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 63/447 [00:28<02:48,  2.28it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 64/447 [00:28<02:48,  2.28it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 65/447 [00:29<02:47,  2.28it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 66/447 [00:29<02:46,  2.28it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 67/447 [00:30<02:46,  2.28it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 68/447 [00:30<02:46,  2.28it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 69/447 [00:31<02:45,  2.28it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 70/447 [00:31<02:45,  2.28it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 71/447 [00:31<02:44,  2.28it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 72/447 [00:32<02:44,  2.28it/s]\u001b[A\n",
      "Iteration:  16%|█▋        | 73/447 [00:32<02:44,  2.28it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 74/447 [00:33<02:43,  2.28it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 75/447 [00:33<02:43,  2.27it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 76/447 [00:34<02:42,  2.28it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 77/447 [00:34<02:42,  2.28it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 78/447 [00:35<02:42,  2.27it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 79/447 [00:35<02:41,  2.28it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 80/447 [00:35<02:41,  2.28it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 81/447 [00:36<02:40,  2.27it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 82/447 [00:36<02:40,  2.28it/s]\u001b[A\n",
      "Iteration:  19%|█▊        | 83/447 [00:37<02:40,  2.27it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 84/447 [00:37<02:39,  2.27it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 85/447 [00:38<02:39,  2.28it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 86/447 [00:38<02:38,  2.27it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 87/447 [00:39<02:38,  2.28it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 88/447 [00:39<02:37,  2.28it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 89/447 [00:39<02:37,  2.28it/s]\u001b[A\n",
      "Iteration:  20%|██        | 90/447 [00:40<02:36,  2.28it/s]\u001b[A\n",
      "Iteration:  20%|██        | 91/447 [00:40<02:36,  2.28it/s]\u001b[A\n",
      "Iteration:  21%|██        | 92/447 [00:41<02:35,  2.28it/s]\u001b[A\n",
      "Iteration:  21%|██        | 93/447 [00:41<02:35,  2.28it/s]\u001b[A\n",
      "Iteration:  21%|██        | 94/447 [00:42<02:35,  2.27it/s]\u001b[A\n",
      "Iteration:  21%|██▏       | 95/447 [00:42<02:34,  2.28it/s]\u001b[A\n",
      "Iteration:  21%|██▏       | 96/447 [00:42<02:34,  2.28it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 97/447 [00:43<02:33,  2.27it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 98/447 [00:43<02:33,  2.28it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 99/447 [00:44<02:33,  2.27it/s]\u001b[AI1023 02:55:57.683959 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-100/config.json\n",
      "I1023 02:55:58.205273 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-100/pytorch_model.bin\n",
      "I1023 02:55:58.233981 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-100\n",
      "\n",
      "Iteration:  22%|██▏       | 100/447 [00:45<03:29,  1.65it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 101/447 [00:45<03:10,  1.82it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 102/447 [00:46<02:58,  1.93it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 103/447 [00:46<02:50,  2.02it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 104/447 [00:47<02:43,  2.09it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 105/447 [00:47<02:39,  2.15it/s]\u001b[A\n",
      "Iteration:  24%|██▎       | 106/447 [00:47<02:36,  2.18it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 107/447 [00:48<02:34,  2.21it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 108/447 [00:48<02:32,  2.23it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 109/447 [00:49<02:30,  2.24it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 110/447 [00:49<02:29,  2.25it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 111/447 [00:50<02:28,  2.26it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 112/447 [00:50<02:28,  2.26it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 113/447 [00:50<02:27,  2.27it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 114/447 [00:51<02:26,  2.27it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 115/447 [00:51<02:26,  2.27it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 116/447 [00:52<02:25,  2.27it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 117/447 [00:52<02:25,  2.27it/s]\u001b[A\n",
      "Iteration:  26%|██▋       | 118/447 [00:53<02:24,  2.27it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 119/447 [00:53<02:24,  2.27it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 120/447 [00:54<02:23,  2.28it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 121/447 [00:54<02:23,  2.27it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 122/447 [00:54<02:23,  2.27it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 123/447 [00:55<02:22,  2.27it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 124/447 [00:55<02:22,  2.27it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 125/447 [00:56<02:21,  2.27it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 126/447 [00:56<02:21,  2.27it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 127/447 [00:57<02:21,  2.27it/s]\u001b[A\n",
      "Iteration:  29%|██▊       | 128/447 [00:57<02:20,  2.27it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 129/447 [00:58<02:20,  2.27it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 130/447 [00:58<02:19,  2.26it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 131/447 [00:58<02:19,  2.27it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 132/447 [00:59<02:19,  2.26it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 133/447 [00:59<02:18,  2.26it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 134/447 [01:00<02:18,  2.27it/s]\u001b[A\n",
      "Iteration:  30%|███       | 135/447 [01:00<02:17,  2.27it/s]\u001b[A\n",
      "Iteration:  30%|███       | 136/447 [01:01<02:16,  2.27it/s]\u001b[A\n",
      "Iteration:  31%|███       | 137/447 [01:01<02:16,  2.27it/s]\u001b[A\n",
      "Iteration:  31%|███       | 138/447 [01:02<02:16,  2.27it/s]\u001b[A\n",
      "Iteration:  31%|███       | 139/447 [01:02<02:15,  2.27it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 140/447 [01:02<02:15,  2.27it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 141/447 [01:03<02:14,  2.27it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 142/447 [01:03<02:14,  2.27it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 143/447 [01:04<02:14,  2.26it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 144/447 [01:04<02:14,  2.26it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 145/447 [01:05<02:13,  2.26it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 146/447 [01:05<02:12,  2.26it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 147/447 [01:05<02:12,  2.26it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 148/447 [01:06<02:12,  2.26it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 149/447 [01:06<02:11,  2.27it/s]\u001b[A\n",
      "Iteration:  34%|███▎      | 150/447 [01:07<02:11,  2.26it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 151/447 [01:07<02:10,  2.27it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 152/447 [01:08<02:10,  2.27it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 153/447 [01:08<02:09,  2.27it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 154/447 [01:09<02:08,  2.27it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 155/447 [01:09<02:08,  2.26it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 156/447 [01:09<02:08,  2.27it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 157/447 [01:10<02:07,  2.27it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 158/447 [01:10<02:07,  2.27it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 159/447 [01:11<02:07,  2.27it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 160/447 [01:11<02:06,  2.26it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 161/447 [01:12<02:06,  2.27it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 162/447 [01:12<02:05,  2.27it/s]\u001b[A\n",
      "Iteration:  36%|███▋      | 163/447 [01:13<02:05,  2.27it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 164/447 [01:13<02:04,  2.27it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 165/447 [01:13<02:04,  2.26it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 166/447 [01:14<02:04,  2.26it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 167/447 [01:14<02:03,  2.26it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 168/447 [01:15<02:03,  2.26it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 169/447 [01:15<02:02,  2.26it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 170/447 [01:16<02:02,  2.26it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 171/447 [01:16<02:02,  2.26it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 172/447 [01:17<02:01,  2.26it/s]\u001b[A\n",
      "Iteration:  39%|███▊      | 173/447 [01:17<02:00,  2.27it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 174/447 [01:17<02:00,  2.27it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 175/447 [01:18<02:00,  2.26it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 176/447 [01:18<01:59,  2.27it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 177/447 [01:19<01:59,  2.26it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 178/447 [01:19<01:58,  2.26it/s]\u001b[A\n",
      "Iteration:  40%|████      | 179/447 [01:20<01:58,  2.26it/s]\u001b[A\n",
      "Iteration:  40%|████      | 180/447 [01:20<01:58,  2.26it/s]\u001b[A\n",
      "Iteration:  40%|████      | 181/447 [01:21<01:57,  2.26it/s]\u001b[A\n",
      "Iteration:  41%|████      | 182/447 [01:21<01:57,  2.26it/s]\u001b[A\n",
      "Iteration:  41%|████      | 183/447 [01:21<01:56,  2.26it/s]\u001b[A\n",
      "Iteration:  41%|████      | 184/447 [01:22<01:56,  2.26it/s]\u001b[A\n",
      "Iteration:  41%|████▏     | 185/447 [01:22<01:55,  2.26it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 186/447 [01:23<01:55,  2.26it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 187/447 [01:23<01:54,  2.26it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 188/447 [01:24<01:54,  2.27it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 189/447 [01:24<01:53,  2.27it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 190/447 [01:24<01:53,  2.26it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 191/447 [01:25<01:52,  2.27it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 192/447 [01:25<01:52,  2.27it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 193/447 [01:26<01:52,  2.27it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 194/447 [01:26<01:51,  2.27it/s]\u001b[A\n",
      "Iteration:  44%|████▎     | 195/447 [01:27<01:51,  2.26it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 196/447 [01:27<01:50,  2.27it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 197/447 [01:28<01:50,  2.26it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 198/447 [01:28<01:50,  2.26it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 199/447 [01:28<01:49,  2.27it/s]\u001b[AI1023 02:56:42.336592 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-200/config.json\n",
      "I1023 02:56:42.857687 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-200/pytorch_model.bin\n",
      "I1023 02:56:42.884966 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-200\n",
      "\n",
      "Iteration:  45%|████▍     | 200/447 [01:29<02:29,  1.65it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 201/447 [01:30<02:15,  1.81it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 202/447 [01:30<02:07,  1.92it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 203/447 [01:31<02:00,  2.02it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 204/447 [01:31<01:56,  2.09it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 205/447 [01:32<01:53,  2.14it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 206/447 [01:32<01:50,  2.18it/s]\u001b[A\n",
      "Iteration:  46%|████▋     | 207/447 [01:33<01:49,  2.20it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 208/447 [01:33<01:47,  2.22it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 209/447 [01:33<01:46,  2.23it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 210/447 [01:34<01:45,  2.25it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 211/447 [01:34<01:44,  2.25it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 212/447 [01:35<01:44,  2.25it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 213/447 [01:35<01:43,  2.26it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 214/447 [01:36<01:43,  2.26it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 215/447 [01:36<01:42,  2.26it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 216/447 [01:36<01:42,  2.26it/s]\u001b[A\n",
      "Iteration:  49%|████▊     | 217/447 [01:37<01:41,  2.26it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 218/447 [01:37<01:41,  2.26it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 219/447 [01:38<01:40,  2.26it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 220/447 [01:38<01:40,  2.27it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 221/447 [01:39<01:39,  2.27it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 222/447 [01:39<01:39,  2.27it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 223/447 [01:40<01:38,  2.26it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 224/447 [01:40<01:38,  2.26it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 225/447 [01:40<01:38,  2.26it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 226/447 [01:41<01:37,  2.27it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 227/447 [01:41<01:37,  2.26it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 228/447 [01:42<01:36,  2.26it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 229/447 [01:42<01:36,  2.26it/s]\u001b[A\n",
      "Iteration:  51%|█████▏    | 230/447 [01:43<01:35,  2.26it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 231/447 [01:43<01:35,  2.26it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 232/447 [01:44<01:35,  2.26it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 233/447 [01:44<01:34,  2.26it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 234/447 [01:44<01:34,  2.26it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 235/447 [01:45<01:33,  2.26it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 236/447 [01:45<01:33,  2.26it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 237/447 [01:46<01:32,  2.26it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 238/447 [01:46<01:32,  2.26it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 239/447 [01:47<01:32,  2.26it/s]\u001b[A\n",
      "Iteration:  54%|█████▎    | 240/447 [01:47<01:31,  2.26it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 241/447 [01:48<01:30,  2.27it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 242/447 [01:48<01:30,  2.26it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 243/447 [01:48<01:30,  2.26it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 244/447 [01:49<01:29,  2.26it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 245/447 [01:49<01:29,  2.26it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 246/447 [01:50<01:28,  2.26it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 247/447 [01:50<01:28,  2.26it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 248/447 [01:51<01:28,  2.26it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 249/447 [01:51<01:27,  2.26it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 250/447 [01:52<01:27,  2.26it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 251/447 [01:52<01:26,  2.26it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 252/447 [01:52<01:26,  2.26it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 253/447 [01:53<01:25,  2.26it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 254/447 [01:53<01:25,  2.26it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 255/447 [01:54<01:24,  2.26it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 256/447 [01:54<01:24,  2.27it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 257/447 [01:55<01:23,  2.26it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 258/447 [01:55<01:23,  2.26it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 259/447 [01:55<01:23,  2.26it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 260/447 [01:56<01:22,  2.26it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 261/447 [01:56<01:22,  2.26it/s]\u001b[A\n",
      "Iteration:  59%|█████▊    | 262/447 [01:57<01:21,  2.26it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 263/447 [01:57<01:21,  2.26it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 264/447 [01:58<01:21,  2.26it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 265/447 [01:58<01:20,  2.26it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 266/447 [01:59<01:20,  2.26it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 267/447 [01:59<01:19,  2.26it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 268/447 [01:59<01:19,  2.24it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 269/447 [02:00<01:19,  2.25it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 270/447 [02:00<01:18,  2.25it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 271/447 [02:01<01:18,  2.25it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 272/447 [02:01<01:17,  2.26it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 273/447 [02:02<01:17,  2.26it/s]\u001b[A\n",
      "Iteration:  61%|██████▏   | 274/447 [02:02<01:16,  2.26it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 275/447 [02:03<01:16,  2.26it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 276/447 [02:03<01:15,  2.26it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 277/447 [02:03<01:15,  2.26it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 278/447 [02:04<01:14,  2.26it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 279/447 [02:04<01:14,  2.26it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 280/447 [02:05<01:13,  2.26it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 281/447 [02:05<01:13,  2.26it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 282/447 [02:06<01:12,  2.26it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 283/447 [02:06<01:12,  2.26it/s]\u001b[A\n",
      "Iteration:  64%|██████▎   | 284/447 [02:07<01:12,  2.26it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 285/447 [02:07<01:11,  2.26it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 286/447 [02:07<01:11,  2.26it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 287/447 [02:08<01:10,  2.26it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 288/447 [02:08<01:10,  2.26it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 289/447 [02:09<01:09,  2.26it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 290/447 [02:09<01:09,  2.26it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 291/447 [02:10<01:08,  2.26it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 292/447 [02:10<01:08,  2.26it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 293/447 [02:11<01:07,  2.27it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 294/447 [02:11<01:07,  2.26it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 295/447 [02:11<01:07,  2.26it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 296/447 [02:12<01:06,  2.26it/s]\u001b[A\n",
      "Iteration:  66%|██████▋   | 297/447 [02:12<01:06,  2.26it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 298/447 [02:13<01:05,  2.26it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 299/447 [02:13<01:05,  2.26it/s]\u001b[AI1023 02:57:27.070192 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-300/config.json\n",
      "I1023 02:57:27.576211 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-300/pytorch_model.bin\n",
      "I1023 02:57:27.603005 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-300\n",
      "\n",
      "Iteration:  67%|██████▋   | 300/447 [02:14<01:28,  1.66it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 301/447 [02:15<01:20,  1.82it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 302/447 [02:15<01:15,  1.93it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 303/447 [02:15<01:11,  2.02it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 304/447 [02:16<01:08,  2.09it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 305/447 [02:16<01:06,  2.13it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 306/447 [02:17<01:04,  2.17it/s]\u001b[A\n",
      "Iteration:  69%|██████▊   | 307/447 [02:17<01:03,  2.19it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 308/447 [02:18<01:02,  2.21it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 309/447 [02:18<01:01,  2.23it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 310/447 [02:19<01:01,  2.24it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 311/447 [02:19<01:00,  2.24it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 312/447 [02:19<00:59,  2.25it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 313/447 [02:20<00:59,  2.25it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 314/447 [02:20<00:58,  2.26it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 315/447 [02:21<00:58,  2.26it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 316/447 [02:21<00:57,  2.26it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 317/447 [02:22<00:57,  2.27it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 318/447 [02:22<00:57,  2.26it/s]\u001b[A\n",
      "Iteration:  71%|███████▏  | 319/447 [02:23<00:56,  2.26it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 320/447 [02:23<00:56,  2.26it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 321/447 [02:23<00:55,  2.26it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 322/447 [02:24<00:55,  2.26it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 323/447 [02:24<00:54,  2.26it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 324/447 [02:25<00:54,  2.26it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 325/447 [02:25<00:54,  2.26it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 326/447 [02:26<00:53,  2.26it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 327/447 [02:26<00:53,  2.26it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 328/447 [02:27<00:52,  2.26it/s]\u001b[A\n",
      "Iteration:  74%|███████▎  | 329/447 [02:27<00:52,  2.26it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 330/447 [02:27<00:51,  2.26it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 331/447 [02:28<00:51,  2.26it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 332/447 [02:28<00:50,  2.26it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 333/447 [02:29<00:50,  2.26it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 334/447 [02:29<00:50,  2.26it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 335/447 [02:30<00:49,  2.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 336/447 [02:30<00:49,  2.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 337/447 [02:31<00:48,  2.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 338/447 [02:31<00:48,  2.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 339/447 [02:31<00:47,  2.26it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 340/447 [02:32<00:47,  2.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▋  | 341/447 [02:32<00:46,  2.26it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 342/447 [02:33<00:46,  2.26it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 343/447 [02:33<00:46,  2.26it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 344/447 [02:34<00:45,  2.26it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 345/447 [02:34<00:45,  2.26it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 346/447 [02:35<00:44,  2.26it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 347/447 [02:35<00:44,  2.26it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 348/447 [02:35<00:43,  2.26it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 349/447 [02:36<00:43,  2.26it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 350/447 [02:36<00:42,  2.26it/s]\u001b[A\n",
      "Iteration:  79%|███████▊  | 351/447 [02:37<00:42,  2.26it/s]\u001b[A\n",
      "Iteration:  79%|███████▊  | 352/447 [02:37<00:42,  2.26it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 353/447 [02:38<00:41,  2.26it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 354/447 [02:38<00:41,  2.26it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 355/447 [02:39<00:40,  2.26it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 356/447 [02:39<00:40,  2.26it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 357/447 [02:39<00:39,  2.25it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 358/447 [02:40<00:39,  2.25it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 359/447 [02:40<00:39,  2.25it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 360/447 [02:41<00:38,  2.26it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 361/447 [02:41<00:38,  2.26it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 362/447 [02:42<00:37,  2.26it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 363/447 [02:42<00:37,  2.26it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 364/447 [02:42<00:36,  2.26it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 365/447 [02:43<00:36,  2.25it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 366/447 [02:43<00:36,  2.24it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 367/447 [02:44<00:35,  2.24it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 368/447 [02:44<00:35,  2.24it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 369/447 [02:45<00:34,  2.24it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 370/447 [02:45<00:34,  2.24it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 371/447 [02:46<00:33,  2.24it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 372/447 [02:46<00:33,  2.25it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 373/447 [02:47<00:32,  2.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▎ | 374/447 [02:47<00:32,  2.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 375/447 [02:47<00:32,  2.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 376/447 [02:48<00:31,  2.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 377/447 [02:48<00:31,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 378/447 [02:49<00:30,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 379/447 [02:49<00:30,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 380/447 [02:50<00:29,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 381/447 [02:50<00:29,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 382/447 [02:51<00:28,  2.25it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 383/447 [02:51<00:28,  2.25it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 384/447 [02:51<00:28,  2.25it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 385/447 [02:52<00:27,  2.25it/s]\u001b[A\n",
      "Iteration:  86%|████████▋ | 386/447 [02:52<00:27,  2.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 387/447 [02:53<00:26,  2.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 388/447 [02:53<00:26,  2.26it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 389/447 [02:54<00:25,  2.26it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 390/447 [02:54<00:25,  2.26it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 391/447 [02:54<00:24,  2.26it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 392/447 [02:55<00:24,  2.26it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 393/447 [02:55<00:23,  2.26it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 394/447 [02:56<00:23,  2.26it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 395/447 [02:56<00:23,  2.26it/s]\u001b[A\n",
      "Iteration:  89%|████████▊ | 396/447 [02:57<00:22,  2.26it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 397/447 [02:57<00:22,  2.26it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 398/447 [02:58<00:21,  2.26it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 399/447 [02:58<00:21,  2.26it/s]\u001b[AI1023 02:58:11.920024 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-400/config.json\n",
      "I1023 02:58:12.454071 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-400/pytorch_model.bin\n",
      "I1023 02:58:12.481475 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-400\n",
      "\n",
      "Iteration:  89%|████████▉ | 400/447 [02:59<00:28,  1.64it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 401/447 [02:59<00:25,  1.80it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 402/447 [03:00<00:23,  1.92it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 403/447 [03:00<00:21,  2.01it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 404/447 [03:01<00:20,  2.08it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 405/447 [03:01<00:19,  2.13it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 406/447 [03:02<00:18,  2.16it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 407/447 [03:02<00:18,  2.19it/s]\u001b[A\n",
      "Iteration:  91%|█████████▏| 408/447 [03:03<00:17,  2.21it/s]\u001b[A\n",
      "Iteration:  91%|█████████▏| 409/447 [03:03<00:17,  2.23it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 410/447 [03:03<00:16,  2.24it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 411/447 [03:04<00:16,  2.24it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 412/447 [03:04<00:15,  2.25it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 413/447 [03:05<00:15,  2.24it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 414/447 [03:05<00:14,  2.25it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 415/447 [03:06<00:14,  2.24it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 416/447 [03:06<00:13,  2.24it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 417/447 [03:07<00:13,  2.24it/s]\u001b[A\n",
      "Iteration:  94%|█████████▎| 418/447 [03:07<00:12,  2.24it/s]\u001b[A\n",
      "Iteration:  94%|█████████▎| 419/447 [03:07<00:12,  2.24it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 420/447 [03:08<00:12,  2.24it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 421/447 [03:08<00:11,  2.25it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 422/447 [03:09<00:11,  2.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 423/447 [03:09<00:10,  2.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 424/447 [03:10<00:10,  2.26it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 425/447 [03:10<00:09,  2.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 426/447 [03:11<00:09,  2.26it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 427/447 [03:11<00:08,  2.26it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 428/447 [03:11<00:08,  2.25it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 429/447 [03:12<00:07,  2.25it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 430/447 [03:12<00:07,  2.26it/s]\u001b[A\n",
      "Iteration:  96%|█████████▋| 431/447 [03:13<00:07,  2.25it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 432/447 [03:13<00:06,  2.25it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 433/447 [03:14<00:06,  2.25it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 434/447 [03:14<00:05,  2.26it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 435/447 [03:15<00:05,  2.26it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 436/447 [03:15<00:04,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 437/447 [03:15<00:04,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 438/447 [03:16<00:04,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 439/447 [03:16<00:03,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 440/447 [03:17<00:03,  2.25it/s]\u001b[A\n",
      "Iteration:  99%|█████████▊| 441/447 [03:17<00:02,  2.25it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 442/447 [03:18<00:02,  2.25it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 443/447 [03:18<00:01,  2.25it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 444/447 [03:19<00:01,  2.25it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 445/447 [03:19<00:00,  2.24it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 446/447 [03:19<00:00,  2.25it/s]\u001b[A\n",
      "Epoch:  33%|███▎      | 1/3 [03:20<06:40, 200.36s/it]\n",
      "Iteration:   0%|          | 0/447 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/447 [00:00<03:14,  2.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 2/447 [00:00<03:14,  2.29it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/447 [00:01<03:14,  2.28it/s]\u001b[A\n",
      "Iteration:   1%|          | 4/447 [00:01<03:14,  2.27it/s]\u001b[A\n",
      "Iteration:   1%|          | 5/447 [00:02<03:14,  2.27it/s]\u001b[A\n",
      "Iteration:   1%|▏         | 6/447 [00:02<03:14,  2.26it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 7/447 [00:03<03:14,  2.26it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 8/447 [00:03<03:14,  2.26it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 9/447 [00:03<03:14,  2.26it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 10/447 [00:04<03:13,  2.26it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 11/447 [00:04<03:13,  2.25it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 12/447 [00:05<03:13,  2.25it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 13/447 [00:05<03:12,  2.25it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 14/447 [00:06<03:12,  2.25it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 15/447 [00:06<03:11,  2.26it/s]\u001b[A\n",
      "Iteration:   4%|▎         | 16/447 [00:07<03:11,  2.26it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 17/447 [00:07<03:10,  2.26it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 18/447 [00:07<03:10,  2.26it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 19/447 [00:08<03:09,  2.26it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 20/447 [00:08<03:08,  2.26it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 21/447 [00:09<03:08,  2.26it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 22/447 [00:09<03:08,  2.26it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 23/447 [00:10<03:07,  2.26it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 24/447 [00:10<03:07,  2.26it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 25/447 [00:11<03:06,  2.26it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 26/447 [00:11<03:06,  2.26it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 27/447 [00:11<03:06,  2.25it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 28/447 [00:12<03:05,  2.26it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 29/447 [00:12<03:05,  2.25it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 30/447 [00:13<03:04,  2.26it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 31/447 [00:13<03:04,  2.26it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 32/447 [00:14<03:04,  2.25it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 33/447 [00:14<03:04,  2.25it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 34/447 [00:15<03:03,  2.25it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 35/447 [00:15<03:03,  2.25it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 36/447 [00:15<03:02,  2.25it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 37/447 [00:16<03:01,  2.25it/s]\u001b[A\n",
      "Iteration:   9%|▊         | 38/447 [00:16<03:01,  2.25it/s]\u001b[A\n",
      "Iteration:   9%|▊         | 39/447 [00:17<03:00,  2.26it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 40/447 [00:17<03:00,  2.26it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 41/447 [00:18<03:00,  2.26it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 42/447 [00:18<02:59,  2.26it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 43/447 [00:19<02:58,  2.26it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 44/447 [00:19<02:58,  2.26it/s]\u001b[A\n",
      "Iteration:  10%|█         | 45/447 [00:19<02:58,  2.26it/s]\u001b[A\n",
      "Iteration:  10%|█         | 46/447 [00:20<02:57,  2.26it/s]\u001b[A\n",
      "Iteration:  11%|█         | 47/447 [00:20<02:57,  2.25it/s]\u001b[A\n",
      "Iteration:  11%|█         | 48/447 [00:21<02:57,  2.25it/s]\u001b[A\n",
      "Iteration:  11%|█         | 49/447 [00:21<02:56,  2.25it/s]\u001b[A\n",
      "Iteration:  11%|█         | 50/447 [00:22<02:56,  2.25it/s]\u001b[A\n",
      "Iteration:  11%|█▏        | 51/447 [00:22<02:55,  2.25it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 52/447 [00:23<02:55,  2.26it/s]\u001b[AI1023 02:58:56.794571 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-500/config.json\n",
      "I1023 02:58:57.313768 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-500/pytorch_model.bin\n",
      "I1023 02:58:57.344928 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-500\n",
      "\n",
      "Iteration:  12%|█▏        | 53/447 [00:24<04:00,  1.64it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 54/447 [00:24<03:38,  1.80it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 55/447 [00:24<03:24,  1.92it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 56/447 [00:25<03:14,  2.01it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 57/447 [00:25<03:08,  2.07it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 58/447 [00:26<03:03,  2.12it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 59/447 [00:26<02:59,  2.16it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 60/447 [00:27<02:57,  2.19it/s]\u001b[A\n",
      "Iteration:  14%|█▎        | 61/447 [00:27<02:55,  2.20it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 62/447 [00:28<02:53,  2.22it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 63/447 [00:28<02:51,  2.23it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 64/447 [00:28<02:51,  2.24it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 65/447 [00:29<02:50,  2.24it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 66/447 [00:29<02:50,  2.24it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 67/447 [00:30<02:49,  2.24it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 68/447 [00:30<02:48,  2.25it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 69/447 [00:31<02:48,  2.25it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 70/447 [00:31<02:47,  2.25it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 71/447 [00:32<02:46,  2.25it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 72/447 [00:32<02:46,  2.25it/s]\u001b[A\n",
      "Iteration:  16%|█▋        | 73/447 [00:32<02:45,  2.25it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 74/447 [00:33<02:45,  2.25it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 75/447 [00:33<02:44,  2.26it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 76/447 [00:34<02:44,  2.25it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 77/447 [00:34<02:43,  2.26it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 78/447 [00:35<02:43,  2.25it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 79/447 [00:35<02:43,  2.26it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 80/447 [00:36<02:42,  2.25it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 81/447 [00:36<02:42,  2.25it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 82/447 [00:36<02:41,  2.26it/s]\u001b[A\n",
      "Iteration:  19%|█▊        | 83/447 [00:37<02:41,  2.26it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 84/447 [00:37<02:40,  2.26it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 85/447 [00:38<02:40,  2.26it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 86/447 [00:38<02:39,  2.26it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 87/447 [00:39<02:39,  2.26it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 88/447 [00:39<02:39,  2.26it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 89/447 [00:40<02:38,  2.26it/s]\u001b[A\n",
      "Iteration:  20%|██        | 90/447 [00:40<02:38,  2.26it/s]\u001b[A\n",
      "Iteration:  20%|██        | 91/447 [00:40<02:37,  2.26it/s]\u001b[A\n",
      "Iteration:  21%|██        | 92/447 [00:41<02:37,  2.26it/s]\u001b[A\n",
      "Iteration:  21%|██        | 93/447 [00:41<02:37,  2.25it/s]\u001b[A\n",
      "Iteration:  21%|██        | 94/447 [00:42<02:36,  2.25it/s]\u001b[A\n",
      "Iteration:  21%|██▏       | 95/447 [00:42<02:36,  2.25it/s]\u001b[A\n",
      "Iteration:  21%|██▏       | 96/447 [00:43<02:35,  2.25it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 97/447 [00:43<02:35,  2.25it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 98/447 [00:43<02:34,  2.25it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 99/447 [00:44<02:34,  2.25it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 100/447 [00:44<02:34,  2.25it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 101/447 [00:45<02:33,  2.25it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 102/447 [00:45<02:33,  2.25it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 103/447 [00:46<02:32,  2.25it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 104/447 [00:46<02:32,  2.25it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 105/447 [00:47<02:31,  2.25it/s]\u001b[A\n",
      "Iteration:  24%|██▎       | 106/447 [00:47<02:31,  2.25it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 107/447 [00:47<02:30,  2.25it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 108/447 [00:48<02:30,  2.26it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 109/447 [00:48<02:29,  2.25it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 110/447 [00:49<02:29,  2.25it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 111/447 [00:49<02:29,  2.25it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 112/447 [00:50<02:29,  2.25it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 113/447 [00:50<02:28,  2.25it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 114/447 [00:51<02:28,  2.25it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 115/447 [00:51<02:27,  2.25it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 116/447 [00:51<02:27,  2.25it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 117/447 [00:52<02:26,  2.25it/s]\u001b[A\n",
      "Iteration:  26%|██▋       | 118/447 [00:52<02:25,  2.25it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 119/447 [00:53<02:25,  2.25it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 120/447 [00:53<02:25,  2.25it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 121/447 [00:54<02:24,  2.25it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 122/447 [00:54<02:24,  2.25it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 123/447 [00:55<02:23,  2.25it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 124/447 [00:55<02:23,  2.25it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 125/447 [00:55<02:22,  2.26it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 126/447 [00:56<02:22,  2.25it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 127/447 [00:56<02:22,  2.25it/s]\u001b[A\n",
      "Iteration:  29%|██▊       | 128/447 [00:57<02:21,  2.25it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 129/447 [00:57<02:21,  2.25it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 130/447 [00:58<02:20,  2.25it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 131/447 [00:58<02:20,  2.25it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 132/447 [00:59<02:19,  2.25it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 133/447 [00:59<02:20,  2.24it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 134/447 [01:00<02:19,  2.24it/s]\u001b[A\n",
      "Iteration:  30%|███       | 135/447 [01:00<02:19,  2.24it/s]\u001b[A\n",
      "Iteration:  30%|███       | 136/447 [01:00<02:18,  2.25it/s]\u001b[A\n",
      "Iteration:  31%|███       | 137/447 [01:01<02:17,  2.25it/s]\u001b[A\n",
      "Iteration:  31%|███       | 138/447 [01:01<02:17,  2.25it/s]\u001b[A\n",
      "Iteration:  31%|███       | 139/447 [01:02<02:16,  2.25it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 140/447 [01:02<02:16,  2.25it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 141/447 [01:03<02:15,  2.25it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 142/447 [01:03<02:15,  2.25it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 143/447 [01:03<02:15,  2.25it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 144/447 [01:04<02:14,  2.25it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 145/447 [01:04<02:14,  2.25it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 146/447 [01:05<02:13,  2.25it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 147/447 [01:05<02:13,  2.25it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 148/447 [01:06<02:12,  2.25it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 149/447 [01:06<02:12,  2.25it/s]\u001b[A\n",
      "Iteration:  34%|███▎      | 150/447 [01:07<02:12,  2.25it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 151/447 [01:07<02:11,  2.25it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 152/447 [01:07<02:11,  2.25it/s]\u001b[AI1023 02:59:41.746128 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-600/config.json\n",
      "I1023 02:59:42.273176 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-600/pytorch_model.bin\n",
      "I1023 02:59:42.303775 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-600\n",
      "\n",
      "Iteration:  34%|███▍      | 153/447 [01:09<03:00,  1.63it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 154/447 [01:09<02:43,  1.79it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 155/447 [01:09<02:33,  1.91it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 156/447 [01:10<02:25,  2.00it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 157/447 [01:10<02:20,  2.07it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 158/447 [01:11<02:16,  2.12it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 159/447 [01:11<02:13,  2.15it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 160/447 [01:12<02:11,  2.18it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 161/447 [01:12<02:09,  2.20it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 162/447 [01:12<02:08,  2.22it/s]\u001b[A\n",
      "Iteration:  36%|███▋      | 163/447 [01:13<02:07,  2.23it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 164/447 [01:13<02:06,  2.23it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 165/447 [01:14<02:05,  2.24it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 166/447 [01:14<02:05,  2.25it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 167/447 [01:15<02:04,  2.25it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 168/447 [01:15<02:03,  2.25it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 169/447 [01:16<02:03,  2.25it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 170/447 [01:16<02:03,  2.25it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 171/447 [01:16<02:02,  2.25it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 172/447 [01:17<02:02,  2.25it/s]\u001b[A\n",
      "Iteration:  39%|███▊      | 173/447 [01:17<02:01,  2.25it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 174/447 [01:18<02:01,  2.25it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 175/447 [01:18<02:00,  2.26it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 176/447 [01:19<02:00,  2.26it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 177/447 [01:19<02:00,  2.25it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 178/447 [01:20<01:59,  2.25it/s]\u001b[A\n",
      "Iteration:  40%|████      | 179/447 [01:20<01:59,  2.25it/s]\u001b[A\n",
      "Iteration:  40%|████      | 180/447 [01:20<01:58,  2.26it/s]\u001b[A\n",
      "Iteration:  40%|████      | 181/447 [01:21<01:58,  2.25it/s]\u001b[A\n",
      "Iteration:  41%|████      | 182/447 [01:21<01:57,  2.25it/s]\u001b[A\n",
      "Iteration:  41%|████      | 183/447 [01:22<01:57,  2.25it/s]\u001b[A\n",
      "Iteration:  41%|████      | 184/447 [01:22<01:56,  2.25it/s]\u001b[A\n",
      "Iteration:  41%|████▏     | 185/447 [01:23<01:56,  2.26it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 186/447 [01:23<01:55,  2.25it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 187/447 [01:24<01:55,  2.26it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 188/447 [01:24<01:55,  2.25it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 189/447 [01:24<01:54,  2.25it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 190/447 [01:25<01:54,  2.25it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 191/447 [01:25<01:53,  2.25it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 192/447 [01:26<01:53,  2.25it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 193/447 [01:26<01:53,  2.24it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 194/447 [01:27<01:52,  2.25it/s]\u001b[A\n",
      "Iteration:  44%|████▎     | 195/447 [01:27<01:52,  2.25it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 196/447 [01:28<01:51,  2.25it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 197/447 [01:28<01:51,  2.25it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 198/447 [01:28<01:50,  2.25it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 199/447 [01:29<01:50,  2.25it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 200/447 [01:29<01:49,  2.25it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 201/447 [01:30<01:49,  2.25it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 202/447 [01:30<01:48,  2.25it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 203/447 [01:31<01:48,  2.26it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 204/447 [01:31<01:47,  2.26it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 205/447 [01:32<01:47,  2.24it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 206/447 [01:32<01:47,  2.24it/s]\u001b[A\n",
      "Iteration:  46%|████▋     | 207/447 [01:32<01:47,  2.24it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 208/447 [01:33<01:46,  2.24it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 209/447 [01:33<01:46,  2.24it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 210/447 [01:34<01:45,  2.25it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 211/447 [01:34<01:45,  2.24it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 212/447 [01:35<01:44,  2.25it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 213/447 [01:35<01:43,  2.25it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 214/447 [01:36<01:43,  2.25it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 215/447 [01:36<01:42,  2.25it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 216/447 [01:36<01:42,  2.25it/s]\u001b[A\n",
      "Iteration:  49%|████▊     | 217/447 [01:37<01:42,  2.25it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 218/447 [01:37<01:41,  2.25it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 219/447 [01:38<01:41,  2.25it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 220/447 [01:38<01:40,  2.26it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 221/447 [01:39<01:40,  2.25it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 222/447 [01:39<01:39,  2.25it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 223/447 [01:40<01:39,  2.25it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 224/447 [01:40<01:39,  2.25it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 225/447 [01:40<01:38,  2.25it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 226/447 [01:41<01:38,  2.25it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 227/447 [01:41<01:37,  2.25it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 228/447 [01:42<01:37,  2.25it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 229/447 [01:42<01:36,  2.25it/s]\u001b[A\n",
      "Iteration:  51%|█████▏    | 230/447 [01:43<01:36,  2.25it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 231/447 [01:43<01:35,  2.25it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 232/447 [01:44<01:35,  2.25it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 233/447 [01:44<01:35,  2.25it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 234/447 [01:44<01:34,  2.25it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 235/447 [01:45<01:34,  2.25it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 236/447 [01:45<01:33,  2.25it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 237/447 [01:46<01:33,  2.25it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 238/447 [01:46<01:32,  2.25it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 239/447 [01:47<01:32,  2.25it/s]\u001b[A\n",
      "Iteration:  54%|█████▎    | 240/447 [01:47<01:31,  2.25it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 241/447 [01:48<01:31,  2.25it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 242/447 [01:48<01:30,  2.25it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 243/447 [01:48<01:30,  2.25it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 244/447 [01:49<01:30,  2.25it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 245/447 [01:49<01:29,  2.25it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 246/447 [01:50<01:29,  2.25it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 247/447 [01:50<01:28,  2.25it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 248/447 [01:51<01:28,  2.25it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 249/447 [01:51<01:27,  2.25it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 250/447 [01:52<01:27,  2.25it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 251/447 [01:52<01:26,  2.25it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 252/447 [01:52<01:26,  2.25it/s]\u001b[AI1023 03:00:26.717708 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-700/config.json\n",
      "I1023 03:00:27.236694 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-700/pytorch_model.bin\n",
      "I1023 03:00:27.264001 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-700\n",
      "\n",
      "Iteration:  57%|█████▋    | 253/447 [01:53<01:58,  1.64it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 254/447 [01:54<01:46,  1.80it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 255/447 [01:54<01:40,  1.92it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 256/447 [01:55<01:35,  2.00it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 257/447 [01:55<01:31,  2.07it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 258/447 [01:56<01:28,  2.12it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 259/447 [01:56<01:26,  2.16it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 260/447 [01:57<01:25,  2.19it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 261/447 [01:57<01:24,  2.21it/s]\u001b[A\n",
      "Iteration:  59%|█████▊    | 262/447 [01:57<01:23,  2.22it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 263/447 [01:58<01:22,  2.23it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 264/447 [01:58<01:21,  2.24it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 265/447 [01:59<01:21,  2.24it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 266/447 [01:59<01:20,  2.24it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 267/447 [02:00<01:20,  2.24it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 268/447 [02:00<01:19,  2.25it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 269/447 [02:01<01:19,  2.25it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 270/447 [02:01<01:18,  2.25it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 271/447 [02:01<01:18,  2.25it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 272/447 [02:02<01:17,  2.25it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 273/447 [02:02<01:17,  2.26it/s]\u001b[A\n",
      "Iteration:  61%|██████▏   | 274/447 [02:03<01:16,  2.26it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 275/447 [02:03<01:16,  2.25it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 276/447 [02:04<01:15,  2.26it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 277/447 [02:04<01:15,  2.25it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 278/447 [02:05<01:14,  2.25it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 279/447 [02:05<01:14,  2.25it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 280/447 [02:05<01:14,  2.26it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 281/447 [02:06<01:13,  2.26it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 282/447 [02:06<01:13,  2.25it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 283/447 [02:07<01:12,  2.26it/s]\u001b[A\n",
      "Iteration:  64%|██████▎   | 284/447 [02:07<01:12,  2.25it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 285/447 [02:08<01:11,  2.26it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 286/447 [02:08<01:11,  2.26it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 287/447 [02:09<01:11,  2.25it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 288/447 [02:09<01:10,  2.26it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 289/447 [02:09<01:10,  2.25it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 290/447 [02:10<01:09,  2.25it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 291/447 [02:10<01:09,  2.25it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 292/447 [02:11<01:08,  2.25it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 293/447 [02:11<01:08,  2.25it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 294/447 [02:12<01:07,  2.25it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 295/447 [02:12<01:07,  2.25it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 296/447 [02:13<01:07,  2.25it/s]\u001b[A\n",
      "Iteration:  66%|██████▋   | 297/447 [02:13<01:06,  2.25it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 298/447 [02:13<01:06,  2.25it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 299/447 [02:14<01:05,  2.25it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 300/447 [02:14<01:05,  2.25it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 301/447 [02:15<01:04,  2.25it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 302/447 [02:15<01:04,  2.25it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 303/447 [02:16<01:03,  2.25it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 304/447 [02:16<01:03,  2.25it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 305/447 [02:17<01:03,  2.25it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 306/447 [02:17<01:02,  2.25it/s]\u001b[A\n",
      "Iteration:  69%|██████▊   | 307/447 [02:17<01:02,  2.25it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 308/447 [02:18<01:01,  2.25it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 309/447 [02:18<01:01,  2.25it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 310/447 [02:19<01:00,  2.25it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 311/447 [02:19<01:00,  2.25it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 312/447 [02:20<00:59,  2.25it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 313/447 [02:20<00:59,  2.25it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 314/447 [02:21<00:59,  2.25it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 315/447 [02:21<00:58,  2.25it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 316/447 [02:21<00:58,  2.26it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 317/447 [02:22<00:57,  2.26it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 318/447 [02:22<00:57,  2.26it/s]\u001b[A\n",
      "Iteration:  71%|███████▏  | 319/447 [02:23<00:56,  2.26it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 320/447 [02:23<00:56,  2.25it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 321/447 [02:24<00:55,  2.25it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 322/447 [02:24<00:55,  2.25it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 323/447 [02:25<00:55,  2.24it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 324/447 [02:25<00:54,  2.25it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 325/447 [02:25<00:54,  2.25it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 326/447 [02:26<00:53,  2.25it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 327/447 [02:26<00:53,  2.25it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 328/447 [02:27<00:52,  2.25it/s]\u001b[A\n",
      "Iteration:  74%|███████▎  | 329/447 [02:27<00:52,  2.25it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 330/447 [02:28<00:52,  2.25it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 331/447 [02:28<00:51,  2.25it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 332/447 [02:29<00:51,  2.25it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 333/447 [02:29<00:50,  2.26it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 334/447 [02:29<00:50,  2.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 335/447 [02:30<00:49,  2.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 336/447 [02:30<00:49,  2.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 337/447 [02:31<00:48,  2.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 338/447 [02:31<00:48,  2.26it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 339/447 [02:32<00:47,  2.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 340/447 [02:32<00:47,  2.26it/s]\u001b[A\n",
      "Iteration:  76%|███████▋  | 341/447 [02:33<00:47,  2.25it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 342/447 [02:33<00:46,  2.25it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 343/447 [02:33<00:46,  2.25it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 344/447 [02:34<00:45,  2.25it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 345/447 [02:34<00:45,  2.26it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 346/447 [02:35<00:44,  2.25it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 347/447 [02:35<00:44,  2.26it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 348/447 [02:36<00:43,  2.25it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 349/447 [02:36<00:43,  2.25it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 350/447 [02:37<00:43,  2.25it/s]\u001b[A\n",
      "Iteration:  79%|███████▊  | 351/447 [02:37<00:42,  2.25it/s]\u001b[A\n",
      "Iteration:  79%|███████▊  | 352/447 [02:37<00:42,  2.25it/s]\u001b[AI1023 03:01:11.642812 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-800/config.json\n",
      "I1023 03:01:12.148597 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-800/pytorch_model.bin\n",
      "I1023 03:01:12.176329 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-800\n",
      "\n",
      "Iteration:  79%|███████▉  | 353/447 [02:38<00:56,  1.65it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 354/447 [02:39<00:51,  1.81it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 355/447 [02:39<00:48,  1.92it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 356/447 [02:40<00:45,  2.01it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 357/447 [02:40<00:43,  2.08it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 358/447 [02:41<00:41,  2.12it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 359/447 [02:41<00:40,  2.16it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 360/447 [02:41<00:39,  2.19it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 361/447 [02:42<00:38,  2.21it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 362/447 [02:42<00:38,  2.22it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 363/447 [02:43<00:37,  2.23it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 364/447 [02:43<00:37,  2.24it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 365/447 [02:44<00:36,  2.24it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 366/447 [02:44<00:36,  2.24it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 367/447 [02:45<00:35,  2.24it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 368/447 [02:45<00:35,  2.24it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 369/447 [02:45<00:34,  2.24it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 370/447 [02:46<00:34,  2.25it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 371/447 [02:46<00:33,  2.25it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 372/447 [02:47<00:33,  2.25it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 373/447 [02:47<00:32,  2.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▎ | 374/447 [02:48<00:32,  2.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 375/447 [02:48<00:31,  2.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 376/447 [02:49<00:31,  2.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 377/447 [02:49<00:31,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 378/447 [02:49<00:30,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 379/447 [02:50<00:30,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 380/447 [02:50<00:29,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 381/447 [02:51<00:29,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 382/447 [02:51<00:28,  2.25it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 383/447 [02:52<00:28,  2.25it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 384/447 [02:52<00:27,  2.25it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 385/447 [02:53<00:27,  2.25it/s]\u001b[A\n",
      "Iteration:  86%|████████▋ | 386/447 [02:53<00:27,  2.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 387/447 [02:53<00:26,  2.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 388/447 [02:54<00:26,  2.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 389/447 [02:54<00:25,  2.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 390/447 [02:55<00:25,  2.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 391/447 [02:55<00:24,  2.25it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 392/447 [02:56<00:24,  2.25it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 393/447 [02:56<00:24,  2.25it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 394/447 [02:57<00:23,  2.24it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 395/447 [02:57<00:23,  2.25it/s]\u001b[A\n",
      "Iteration:  89%|████████▊ | 396/447 [02:57<00:22,  2.25it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 397/447 [02:58<00:22,  2.25it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 398/447 [02:58<00:21,  2.25it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 399/447 [02:59<00:21,  2.25it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 400/447 [02:59<00:20,  2.25it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 401/447 [03:00<00:20,  2.25it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 402/447 [03:00<00:19,  2.25it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 403/447 [03:01<00:19,  2.26it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 404/447 [03:01<00:19,  2.25it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 405/447 [03:01<00:18,  2.25it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 406/447 [03:02<00:18,  2.26it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 407/447 [03:02<00:17,  2.25it/s]\u001b[A\n",
      "Iteration:  91%|█████████▏| 408/447 [03:03<00:17,  2.25it/s]\u001b[A\n",
      "Iteration:  91%|█████████▏| 409/447 [03:03<00:16,  2.25it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 410/447 [03:04<00:16,  2.25it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 411/447 [03:04<00:15,  2.25it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 412/447 [03:05<00:15,  2.25it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 413/447 [03:05<00:15,  2.25it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 414/447 [03:05<00:14,  2.25it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 415/447 [03:06<00:14,  2.25it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 416/447 [03:06<00:13,  2.25it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 417/447 [03:07<00:13,  2.25it/s]\u001b[A\n",
      "Iteration:  94%|█████████▎| 418/447 [03:07<00:12,  2.25it/s]\u001b[A\n",
      "Iteration:  94%|█████████▎| 419/447 [03:08<00:12,  2.25it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 420/447 [03:08<00:11,  2.25it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 421/447 [03:09<00:11,  2.25it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 422/447 [03:09<00:11,  2.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 423/447 [03:09<00:10,  2.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 424/447 [03:10<00:10,  2.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 425/447 [03:10<00:09,  2.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 426/447 [03:11<00:09,  2.25it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 427/447 [03:11<00:08,  2.26it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 428/447 [03:12<00:08,  2.25it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 429/447 [03:12<00:07,  2.25it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 430/447 [03:13<00:07,  2.25it/s]\u001b[A\n",
      "Iteration:  96%|█████████▋| 431/447 [03:13<00:07,  2.26it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 432/447 [03:13<00:06,  2.26it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 433/447 [03:14<00:06,  2.25it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 434/447 [03:14<00:05,  2.25it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 435/447 [03:15<00:05,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 436/447 [03:15<00:04,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 437/447 [03:16<00:04,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 438/447 [03:16<00:03,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 439/447 [03:17<00:03,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 440/447 [03:17<00:03,  2.25it/s]\u001b[A\n",
      "Iteration:  99%|█████████▊| 441/447 [03:17<00:02,  2.25it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 442/447 [03:18<00:02,  2.24it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 443/447 [03:18<00:01,  2.25it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 444/447 [03:19<00:01,  2.24it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 445/447 [03:19<00:00,  2.25it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 446/447 [03:20<00:00,  2.25it/s]\u001b[A\n",
      "Epoch:  67%|██████▋   | 2/3 [06:40<03:20, 200.43s/it]\n",
      "Iteration:   0%|          | 0/447 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/447 [00:00<03:15,  2.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 2/447 [00:00<03:15,  2.27it/s]\u001b[A\n",
      "Iteration:   1%|          | 3/447 [00:01<03:15,  2.27it/s]\u001b[A\n",
      "Iteration:   1%|          | 4/447 [00:01<03:15,  2.26it/s]\u001b[A\n",
      "Iteration:   1%|          | 5/447 [00:02<03:15,  2.26it/s]\u001b[AI1023 03:01:56.563950 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-900/config.json\n",
      "I1023 03:01:57.082494 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-900/pytorch_model.bin\n",
      "I1023 03:01:57.109732 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-900\n",
      "\n",
      "Iteration:   1%|▏         | 6/447 [00:03<04:28,  1.64it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 7/447 [00:03<04:04,  1.80it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 8/447 [00:04<03:48,  1.92it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 9/447 [00:04<03:38,  2.01it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 10/447 [00:04<03:30,  2.07it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 11/447 [00:05<03:25,  2.12it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 12/447 [00:05<03:21,  2.16it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 13/447 [00:06<03:18,  2.19it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 14/447 [00:06<03:16,  2.21it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 15/447 [00:07<03:14,  2.22it/s]\u001b[A\n",
      "Iteration:   4%|▎         | 16/447 [00:07<03:13,  2.23it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 17/447 [00:08<03:12,  2.23it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 18/447 [00:08<03:11,  2.24it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 19/447 [00:08<03:11,  2.24it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 20/447 [00:09<03:10,  2.24it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 21/447 [00:09<03:09,  2.24it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 22/447 [00:10<03:08,  2.25it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 23/447 [00:10<03:08,  2.25it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 24/447 [00:11<03:08,  2.25it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 25/447 [00:11<03:07,  2.25it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 26/447 [00:12<03:07,  2.25it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 27/447 [00:12<03:06,  2.25it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 28/447 [00:12<03:06,  2.25it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 29/447 [00:13<03:05,  2.25it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 30/447 [00:13<03:05,  2.25it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 31/447 [00:14<03:04,  2.25it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 32/447 [00:14<03:04,  2.25it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 33/447 [00:15<03:03,  2.25it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 34/447 [00:15<03:03,  2.25it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 35/447 [00:16<03:03,  2.25it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 36/447 [00:16<03:02,  2.25it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 37/447 [00:16<03:02,  2.25it/s]\u001b[A\n",
      "Iteration:   9%|▊         | 38/447 [00:17<03:01,  2.25it/s]\u001b[A\n",
      "Iteration:   9%|▊         | 39/447 [00:17<03:01,  2.25it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 40/447 [00:18<03:00,  2.25it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 41/447 [00:18<03:00,  2.25it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 42/447 [00:19<03:00,  2.25it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 43/447 [00:19<02:59,  2.25it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 44/447 [00:20<02:58,  2.25it/s]\u001b[A\n",
      "Iteration:  10%|█         | 45/447 [00:20<02:58,  2.25it/s]\u001b[A\n",
      "Iteration:  10%|█         | 46/447 [00:20<02:57,  2.25it/s]\u001b[A\n",
      "Iteration:  11%|█         | 47/447 [00:21<02:57,  2.25it/s]\u001b[A\n",
      "Iteration:  11%|█         | 48/447 [00:21<02:56,  2.26it/s]\u001b[A\n",
      "Iteration:  11%|█         | 49/447 [00:22<02:56,  2.25it/s]\u001b[A\n",
      "Iteration:  11%|█         | 50/447 [00:22<02:56,  2.25it/s]\u001b[A\n",
      "Iteration:  11%|█▏        | 51/447 [00:23<02:55,  2.26it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 52/447 [00:23<02:55,  2.25it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 53/447 [00:24<02:54,  2.25it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 54/447 [00:24<02:54,  2.25it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 55/447 [00:24<02:53,  2.25it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 56/447 [00:25<02:53,  2.25it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 57/447 [00:25<02:53,  2.25it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 58/447 [00:26<02:52,  2.26it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 59/447 [00:26<02:52,  2.25it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 60/447 [00:27<02:51,  2.25it/s]\u001b[A\n",
      "Iteration:  14%|█▎        | 61/447 [00:27<02:51,  2.25it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 62/447 [00:28<02:51,  2.25it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 63/447 [00:28<02:50,  2.25it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 64/447 [00:28<02:50,  2.25it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 65/447 [00:29<02:49,  2.25it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 66/447 [00:29<02:49,  2.25it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 67/447 [00:30<02:48,  2.25it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 68/447 [00:30<02:48,  2.25it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 69/447 [00:31<02:47,  2.26it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 70/447 [00:31<02:47,  2.26it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 71/447 [00:32<02:46,  2.25it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 72/447 [00:32<02:46,  2.25it/s]\u001b[A\n",
      "Iteration:  16%|█▋        | 73/447 [00:32<02:46,  2.25it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 74/447 [00:33<02:45,  2.26it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 75/447 [00:33<02:44,  2.26it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 76/447 [00:34<02:44,  2.25it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 77/447 [00:34<02:43,  2.26it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 78/447 [00:35<02:43,  2.25it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 79/447 [00:35<02:43,  2.26it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 80/447 [00:36<02:42,  2.26it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 81/447 [00:36<02:42,  2.26it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 82/447 [00:36<02:41,  2.26it/s]\u001b[A\n",
      "Iteration:  19%|█▊        | 83/447 [00:37<02:41,  2.25it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 84/447 [00:37<02:41,  2.25it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 85/447 [00:38<02:40,  2.25it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 86/447 [00:38<02:40,  2.25it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 87/447 [00:39<02:40,  2.24it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 88/447 [00:39<02:40,  2.24it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 89/447 [00:40<02:39,  2.25it/s]\u001b[A\n",
      "Iteration:  20%|██        | 90/447 [00:40<02:38,  2.25it/s]\u001b[A\n",
      "Iteration:  20%|██        | 91/447 [00:40<02:38,  2.24it/s]\u001b[A\n",
      "Iteration:  21%|██        | 92/447 [00:41<02:38,  2.25it/s]\u001b[A\n",
      "Iteration:  21%|██        | 93/447 [00:41<02:37,  2.25it/s]\u001b[A\n",
      "Iteration:  21%|██        | 94/447 [00:42<02:36,  2.25it/s]\u001b[A\n",
      "Iteration:  21%|██▏       | 95/447 [00:42<02:36,  2.25it/s]\u001b[A\n",
      "Iteration:  21%|██▏       | 96/447 [00:43<02:35,  2.26it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 97/447 [00:43<02:35,  2.25it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 98/447 [00:44<02:35,  2.25it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 99/447 [00:44<02:34,  2.25it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 100/447 [00:44<02:34,  2.25it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 101/447 [00:45<02:33,  2.25it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 102/447 [00:45<02:33,  2.25it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 103/447 [00:46<02:32,  2.25it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 104/447 [00:46<02:32,  2.25it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 105/447 [00:47<02:31,  2.25it/s]\u001b[AI1023 03:02:41.510328 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-1000/config.json\n",
      "I1023 03:02:42.030183 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-1000/pytorch_model.bin\n",
      "I1023 03:02:42.056339 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-1000\n",
      "\n",
      "Iteration:  24%|██▎       | 106/447 [00:48<03:27,  1.64it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 107/447 [00:48<03:08,  1.81it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 108/447 [00:49<02:56,  1.92it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 109/447 [00:49<02:48,  2.01it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 110/447 [00:49<02:42,  2.08it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 111/447 [00:50<02:38,  2.13it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 112/447 [00:50<02:34,  2.16it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 113/447 [00:51<02:32,  2.19it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 114/447 [00:51<02:30,  2.21it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 115/447 [00:52<02:29,  2.22it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 116/447 [00:52<02:28,  2.23it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 117/447 [00:53<02:27,  2.24it/s]\u001b[A\n",
      "Iteration:  26%|██▋       | 118/447 [00:53<02:26,  2.24it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 119/447 [00:53<02:25,  2.25it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 120/447 [00:54<02:25,  2.25it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 121/447 [00:54<02:24,  2.25it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 122/447 [00:55<02:24,  2.25it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 123/447 [00:55<02:23,  2.25it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 124/447 [00:56<02:23,  2.26it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 125/447 [00:56<02:22,  2.25it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 126/447 [00:57<02:22,  2.25it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 127/447 [00:57<02:22,  2.25it/s]\u001b[A\n",
      "Iteration:  29%|██▊       | 128/447 [00:57<02:21,  2.25it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 129/447 [00:58<02:21,  2.25it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 130/447 [00:58<02:20,  2.25it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 131/447 [00:59<02:20,  2.24it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 132/447 [00:59<02:20,  2.25it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 133/447 [01:00<02:19,  2.25it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 134/447 [01:00<02:19,  2.25it/s]\u001b[A\n",
      "Iteration:  30%|███       | 135/447 [01:01<02:18,  2.25it/s]\u001b[A\n",
      "Iteration:  30%|███       | 136/447 [01:01<02:18,  2.25it/s]\u001b[A\n",
      "Iteration:  31%|███       | 137/447 [01:01<02:17,  2.25it/s]\u001b[A\n",
      "Iteration:  31%|███       | 138/447 [01:02<02:17,  2.25it/s]\u001b[A\n",
      "Iteration:  31%|███       | 139/447 [01:02<02:16,  2.25it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 140/447 [01:03<02:16,  2.25it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 141/447 [01:03<02:15,  2.25it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 142/447 [01:04<02:15,  2.25it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 143/447 [01:04<02:15,  2.25it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 144/447 [01:05<02:14,  2.25it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 145/447 [01:05<02:14,  2.25it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 146/447 [01:05<02:13,  2.25it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 147/447 [01:06<02:13,  2.25it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 148/447 [01:06<02:13,  2.25it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 149/447 [01:07<02:12,  2.25it/s]\u001b[A\n",
      "Iteration:  34%|███▎      | 150/447 [01:07<02:11,  2.25it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 151/447 [01:08<02:11,  2.25it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 152/447 [01:08<02:10,  2.25it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 153/447 [01:09<02:10,  2.25it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 154/447 [01:09<02:10,  2.25it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 155/447 [01:09<02:09,  2.25it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 156/447 [01:10<02:09,  2.25it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 157/447 [01:10<02:08,  2.25it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 158/447 [01:11<02:08,  2.25it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 159/447 [01:11<02:07,  2.25it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 160/447 [01:12<02:07,  2.25it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 161/447 [01:12<02:07,  2.25it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 162/447 [01:13<02:06,  2.25it/s]\u001b[A\n",
      "Iteration:  36%|███▋      | 163/447 [01:13<02:06,  2.25it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 164/447 [01:13<02:05,  2.25it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 165/447 [01:14<02:05,  2.25it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 166/447 [01:14<02:04,  2.25it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 167/447 [01:15<02:04,  2.25it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 168/447 [01:15<02:03,  2.26it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 169/447 [01:16<02:03,  2.26it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 170/447 [01:16<02:02,  2.26it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 171/447 [01:16<02:02,  2.26it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 172/447 [01:17<02:01,  2.26it/s]\u001b[A\n",
      "Iteration:  39%|███▊      | 173/447 [01:17<02:01,  2.26it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 174/447 [01:18<02:01,  2.25it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 175/447 [01:18<02:00,  2.25it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 176/447 [01:19<02:00,  2.25it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 177/447 [01:19<02:00,  2.25it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 178/447 [01:20<01:59,  2.25it/s]\u001b[A\n",
      "Iteration:  40%|████      | 179/447 [01:20<01:59,  2.25it/s]\u001b[A\n",
      "Iteration:  40%|████      | 180/447 [01:21<01:59,  2.24it/s]\u001b[A\n",
      "Iteration:  40%|████      | 181/447 [01:21<01:59,  2.23it/s]\u001b[A\n",
      "Iteration:  41%|████      | 182/447 [01:21<01:58,  2.24it/s]\u001b[A\n",
      "Iteration:  41%|████      | 183/447 [01:22<01:57,  2.24it/s]\u001b[A\n",
      "Iteration:  41%|████      | 184/447 [01:22<01:57,  2.24it/s]\u001b[A\n",
      "Iteration:  41%|████▏     | 185/447 [01:23<01:56,  2.24it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 186/447 [01:23<01:56,  2.25it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 187/447 [01:24<01:55,  2.25it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 188/447 [01:24<01:55,  2.25it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 189/447 [01:25<01:54,  2.25it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 190/447 [01:25<01:54,  2.25it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 191/447 [01:25<01:53,  2.25it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 192/447 [01:26<01:53,  2.25it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 193/447 [01:26<01:52,  2.25it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 194/447 [01:27<01:52,  2.25it/s]\u001b[A\n",
      "Iteration:  44%|████▎     | 195/447 [01:27<01:51,  2.25it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 196/447 [01:28<01:51,  2.25it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 197/447 [01:28<01:50,  2.25it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 198/447 [01:29<01:50,  2.25it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 199/447 [01:29<01:50,  2.24it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 200/447 [01:29<01:49,  2.25it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 201/447 [01:30<01:49,  2.25it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 202/447 [01:30<01:48,  2.25it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 203/447 [01:31<01:48,  2.25it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 204/447 [01:31<01:48,  2.25it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 205/447 [01:32<01:47,  2.25it/s]\u001b[AI1023 03:03:26.465424 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-1100/config.json\n",
      "I1023 03:03:26.994216 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-1100/pytorch_model.bin\n",
      "I1023 03:03:27.021101 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-1100\n",
      "\n",
      "Iteration:  46%|████▌     | 206/447 [01:33<02:27,  1.63it/s]\u001b[A\n",
      "Iteration:  46%|████▋     | 207/447 [01:33<02:13,  1.79it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 208/447 [01:33<02:05,  1.91it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 209/447 [01:34<01:59,  1.99it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 210/447 [01:34<01:55,  2.06it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 211/447 [01:35<01:51,  2.12it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 212/447 [01:35<01:49,  2.15it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 213/447 [01:36<01:47,  2.18it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 214/447 [01:36<01:45,  2.20it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 215/447 [01:37<01:44,  2.22it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 216/447 [01:37<01:43,  2.23it/s]\u001b[A\n",
      "Iteration:  49%|████▊     | 217/447 [01:38<01:42,  2.24it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 218/447 [01:38<01:42,  2.24it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 219/447 [01:38<01:41,  2.24it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 220/447 [01:39<01:41,  2.25it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 221/447 [01:39<01:40,  2.25it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 222/447 [01:40<01:40,  2.25it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 223/447 [01:40<01:39,  2.25it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 224/447 [01:41<01:39,  2.25it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 225/447 [01:41<01:38,  2.25it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 226/447 [01:41<01:38,  2.25it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 227/447 [01:42<01:37,  2.25it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 228/447 [01:42<01:37,  2.25it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 229/447 [01:43<01:37,  2.24it/s]\u001b[A\n",
      "Iteration:  51%|█████▏    | 230/447 [01:43<01:36,  2.24it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 231/447 [01:44<01:36,  2.24it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 232/447 [01:44<01:36,  2.24it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 233/447 [01:45<01:35,  2.24it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 234/447 [01:45<01:34,  2.24it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 235/447 [01:46<01:34,  2.25it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 236/447 [01:46<01:33,  2.25it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 237/447 [01:46<01:33,  2.25it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 238/447 [01:47<01:32,  2.25it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 239/447 [01:47<01:32,  2.25it/s]\u001b[A\n",
      "Iteration:  54%|█████▎    | 240/447 [01:48<01:31,  2.25it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 241/447 [01:48<01:31,  2.25it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 242/447 [01:49<01:31,  2.25it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 243/447 [01:49<01:30,  2.25it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 244/447 [01:50<01:30,  2.25it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 245/447 [01:50<01:29,  2.25it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 246/447 [01:50<01:29,  2.25it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 247/447 [01:51<01:28,  2.25it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 248/447 [01:51<01:28,  2.25it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 249/447 [01:52<01:28,  2.25it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 250/447 [01:52<01:27,  2.25it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 251/447 [01:53<01:27,  2.25it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 252/447 [01:53<01:27,  2.24it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 253/447 [01:54<01:26,  2.24it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 254/447 [01:54<01:25,  2.25it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 255/447 [01:54<01:25,  2.25it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 256/447 [01:55<01:25,  2.24it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 257/447 [01:55<01:24,  2.25it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 258/447 [01:56<01:24,  2.25it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 259/447 [01:56<01:23,  2.25it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 260/447 [01:57<01:23,  2.25it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 261/447 [01:57<01:22,  2.25it/s]\u001b[A\n",
      "Iteration:  59%|█████▊    | 262/447 [01:58<01:22,  2.25it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 263/447 [01:58<01:21,  2.25it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 264/447 [01:58<01:21,  2.25it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 265/447 [01:59<01:20,  2.25it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 266/447 [01:59<01:20,  2.25it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 267/447 [02:00<01:19,  2.25it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 268/447 [02:00<01:19,  2.25it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 269/447 [02:01<01:19,  2.25it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 270/447 [02:01<01:18,  2.25it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 271/447 [02:02<01:18,  2.25it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 272/447 [02:02<01:17,  2.25it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 273/447 [02:02<01:17,  2.25it/s]\u001b[A\n",
      "Iteration:  61%|██████▏   | 274/447 [02:03<01:16,  2.25it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 275/447 [02:03<01:16,  2.25it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 276/447 [02:04<01:15,  2.25it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 277/447 [02:04<01:15,  2.25it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 278/447 [02:05<01:15,  2.25it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 279/447 [02:05<01:14,  2.25it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 280/447 [02:06<01:14,  2.25it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 281/447 [02:06<01:13,  2.25it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 282/447 [02:06<01:13,  2.25it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 283/447 [02:07<01:12,  2.25it/s]\u001b[A\n",
      "Iteration:  64%|██████▎   | 284/447 [02:07<01:12,  2.24it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 285/447 [02:08<01:12,  2.25it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 286/447 [02:08<01:11,  2.24it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 287/447 [02:09<01:11,  2.24it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 288/447 [02:09<01:10,  2.25it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 289/447 [02:10<01:10,  2.25it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 290/447 [02:10<01:09,  2.25it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 291/447 [02:10<01:09,  2.25it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 292/447 [02:11<01:08,  2.25it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 293/447 [02:11<01:08,  2.25it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 294/447 [02:12<01:07,  2.25it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 295/447 [02:12<01:07,  2.25it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 296/447 [02:13<01:06,  2.26it/s]\u001b[A\n",
      "Iteration:  66%|██████▋   | 297/447 [02:13<01:06,  2.25it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 298/447 [02:14<01:06,  2.25it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 299/447 [02:14<01:05,  2.25it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 300/447 [02:14<01:05,  2.25it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 301/447 [02:15<01:04,  2.25it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 302/447 [02:15<01:04,  2.25it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 303/447 [02:16<01:03,  2.26it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 304/447 [02:16<01:03,  2.25it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 305/447 [02:17<01:02,  2.26it/s]\u001b[AI1023 03:04:11.461882 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-1200/config.json\n",
      "I1023 03:04:11.979035 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-1200/pytorch_model.bin\n",
      "I1023 03:04:12.008382 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-1200\n",
      "\n",
      "Iteration:  68%|██████▊   | 306/447 [02:18<01:25,  1.64it/s]\u001b[A\n",
      "Iteration:  69%|██████▊   | 307/447 [02:18<01:17,  1.80it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 308/447 [02:18<01:12,  1.91it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 309/447 [02:19<01:08,  2.00it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 310/447 [02:19<01:06,  2.07it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 311/447 [02:20<01:03,  2.13it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 312/447 [02:20<01:02,  2.16it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 313/447 [02:21<01:01,  2.19it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 314/447 [02:21<01:00,  2.21it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 315/447 [02:22<00:59,  2.22it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 316/447 [02:22<00:58,  2.23it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 317/447 [02:22<00:58,  2.24it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 318/447 [02:23<00:57,  2.24it/s]\u001b[A\n",
      "Iteration:  71%|███████▏  | 319/447 [02:23<00:57,  2.24it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 320/447 [02:24<00:56,  2.24it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 321/447 [02:24<00:56,  2.24it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 322/447 [02:25<00:55,  2.24it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 323/447 [02:25<00:55,  2.25it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 324/447 [02:26<00:54,  2.25it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 325/447 [02:26<00:54,  2.25it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 326/447 [02:26<00:53,  2.25it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 327/447 [02:27<00:53,  2.25it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 328/447 [02:27<00:52,  2.25it/s]\u001b[A\n",
      "Iteration:  74%|███████▎  | 329/447 [02:28<00:52,  2.25it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 330/447 [02:28<00:52,  2.24it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 331/447 [02:29<00:51,  2.25it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 332/447 [02:29<00:51,  2.25it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 333/447 [02:30<00:50,  2.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 334/447 [02:30<00:50,  2.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 335/447 [02:30<00:49,  2.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 336/447 [02:31<00:49,  2.25it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 337/447 [02:31<00:48,  2.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 338/447 [02:32<00:48,  2.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 339/447 [02:32<00:47,  2.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 340/447 [02:33<00:47,  2.25it/s]\u001b[A\n",
      "Iteration:  76%|███████▋  | 341/447 [02:33<00:47,  2.25it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 342/447 [02:34<00:46,  2.25it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 343/447 [02:34<00:46,  2.25it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 344/447 [02:34<00:45,  2.25it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 345/447 [02:35<00:45,  2.26it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 346/447 [02:35<00:44,  2.25it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 347/447 [02:36<00:44,  2.26it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 348/447 [02:36<00:44,  2.25it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 349/447 [02:37<00:43,  2.25it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 350/447 [02:37<00:43,  2.25it/s]\u001b[A\n",
      "Iteration:  79%|███████▊  | 351/447 [02:38<00:42,  2.25it/s]\u001b[A\n",
      "Iteration:  79%|███████▊  | 352/447 [02:38<00:42,  2.26it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 353/447 [02:38<00:41,  2.25it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 354/447 [02:39<00:41,  2.26it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 355/447 [02:39<00:40,  2.25it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 356/447 [02:40<00:40,  2.25it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 357/447 [02:40<00:39,  2.26it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 358/447 [02:41<00:39,  2.25it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 359/447 [02:41<00:39,  2.25it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 360/447 [02:42<00:38,  2.25it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 361/447 [02:42<00:38,  2.25it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 362/447 [02:42<00:37,  2.25it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 363/447 [02:43<00:37,  2.25it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 364/447 [02:43<00:36,  2.25it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 365/447 [02:44<00:36,  2.25it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 366/447 [02:44<00:36,  2.25it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 367/447 [02:45<00:35,  2.25it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 368/447 [02:45<00:35,  2.25it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 369/447 [02:46<00:34,  2.25it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 370/447 [02:46<00:34,  2.25it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 371/447 [02:46<00:33,  2.25it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 372/447 [02:47<00:33,  2.25it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 373/447 [02:47<00:32,  2.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▎ | 374/447 [02:48<00:32,  2.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 375/447 [02:48<00:32,  2.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 376/447 [02:49<00:31,  2.25it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 377/447 [02:49<00:31,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 378/447 [02:50<00:30,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 379/447 [02:50<00:30,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 380/447 [02:50<00:29,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 381/447 [02:51<00:29,  2.25it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 382/447 [02:51<00:28,  2.25it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 383/447 [02:52<00:28,  2.26it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 384/447 [02:52<00:27,  2.25it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 385/447 [02:53<00:27,  2.26it/s]\u001b[A\n",
      "Iteration:  86%|████████▋ | 386/447 [02:53<00:27,  2.26it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 387/447 [02:54<00:26,  2.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 388/447 [02:54<00:26,  2.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 389/447 [02:54<00:25,  2.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 390/447 [02:55<00:25,  2.25it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 391/447 [02:55<00:24,  2.25it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 392/447 [02:56<00:24,  2.25it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 393/447 [02:56<00:24,  2.25it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 394/447 [02:57<00:23,  2.25it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 395/447 [02:57<00:23,  2.25it/s]\u001b[A\n",
      "Iteration:  89%|████████▊ | 396/447 [02:58<00:22,  2.25it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 397/447 [02:58<00:22,  2.26it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 398/447 [02:58<00:21,  2.25it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 399/447 [02:59<00:21,  2.25it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 400/447 [02:59<00:20,  2.25it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 401/447 [03:00<00:20,  2.25it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 402/447 [03:00<00:19,  2.26it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 403/447 [03:01<00:19,  2.25it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 404/447 [03:01<00:19,  2.26it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 405/447 [03:02<00:18,  2.25it/s]\u001b[AI1023 03:04:56.398564 139701840725760 configuration_utils.py:71] Configuration saved in /floyd/home/model/bert-model/checkpoint-1300/config.json\n",
      "I1023 03:04:56.903979 139701840725760 modeling_utils.py:205] Model weights saved in /floyd/home/model/bert-model/checkpoint-1300/pytorch_model.bin\n",
      "I1023 03:04:56.930657 139701840725760 <ipython-input-12-7408f09bfb68>:67] Saving model checkpoint to /floyd/home/model/bert-model/checkpoint-1300\n",
      "\n",
      "Iteration:  91%|█████████ | 406/447 [03:03<00:24,  1.66it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 407/447 [03:03<00:22,  1.82it/s]\u001b[A\n",
      "Iteration:  91%|█████████▏| 408/447 [03:03<00:20,  1.93it/s]\u001b[A\n",
      "Iteration:  91%|█████████▏| 409/447 [03:04<00:18,  2.02it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 410/447 [03:04<00:17,  2.08it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 411/447 [03:05<00:16,  2.13it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 412/447 [03:05<00:16,  2.17it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 413/447 [03:06<00:15,  2.20it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 414/447 [03:06<00:14,  2.21it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 415/447 [03:07<00:14,  2.22it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 416/447 [03:07<00:13,  2.23it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 417/447 [03:07<00:13,  2.24it/s]\u001b[A\n",
      "Iteration:  94%|█████████▎| 418/447 [03:08<00:12,  2.24it/s]\u001b[A\n",
      "Iteration:  94%|█████████▎| 419/447 [03:08<00:12,  2.24it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 420/447 [03:09<00:12,  2.25it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 421/447 [03:09<00:11,  2.25it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 422/447 [03:10<00:11,  2.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 423/447 [03:10<00:10,  2.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 424/447 [03:11<00:10,  2.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 425/447 [03:11<00:09,  2.25it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 426/447 [03:11<00:09,  2.25it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 427/447 [03:12<00:08,  2.26it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 428/447 [03:12<00:08,  2.26it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 429/447 [03:13<00:07,  2.26it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 430/447 [03:13<00:07,  2.25it/s]\u001b[A\n",
      "Iteration:  96%|█████████▋| 431/447 [03:14<00:07,  2.24it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 432/447 [03:14<00:06,  2.24it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 433/447 [03:15<00:06,  2.25it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 434/447 [03:15<00:05,  2.25it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 435/447 [03:15<00:05,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 436/447 [03:16<00:04,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 437/447 [03:16<00:04,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 438/447 [03:17<00:03,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 439/447 [03:17<00:03,  2.25it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 440/447 [03:18<00:03,  2.25it/s]\u001b[A\n",
      "Iteration:  99%|█████████▊| 441/447 [03:18<00:02,  2.25it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 442/447 [03:18<00:02,  2.25it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 443/447 [03:19<00:01,  2.25it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 444/447 [03:19<00:01,  2.25it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 445/447 [03:20<00:00,  2.25it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 446/447 [03:20<00:00,  2.26it/s]\u001b[A\n",
      "Epoch: 100%|██████████| 3/3 [10:02<00:00, 200.65s/it]\n",
      "I1023 03:05:15.079206 139701840725760 <ipython-input-13-a51c721485c6>:4]  global_step = 1341, average loss = 1.731443658237756\n"
     ]
    }
   ],
   "source": [
    "set_seed(args)\n",
    "train_dataset = get_examples_dataset(train_examples, label_list, tokenizer)\n",
    "global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
    "logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load generated model for evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1024 09:10:57.304348 140208979011328 tokenization_utils.py:306] Model name '/floyd/home/model/bert-model' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming '/floyd/home/model/bert-model' is a path or url to a directory containing tokenizer files.\n",
      "I1024 09:10:57.305900 140208979011328 tokenization_utils.py:371] loading file /floyd/home/model/bert-model/vocab.txt\n",
      "I1024 09:10:57.307088 140208979011328 tokenization_utils.py:371] loading file /floyd/home/model/bert-model/added_tokens.json\n",
      "I1024 09:10:57.308177 140208979011328 tokenization_utils.py:371] loading file /floyd/home/model/bert-model/special_tokens_map.json\n",
      "I1024 09:10:57.309315 140208979011328 tokenization_utils.py:371] loading file /floyd/home/model/bert-model/tokenizer_config.json\n",
      "I1024 09:10:57.345602 140208979011328 <ipython-input-7-9a70535d1c4a>:49] Writing example 0\n",
      "I1024 09:10:57.346573 140208979011328 <ipython-input-7-9a70535d1c4a>:81] *** Example ***\n",
      "I1024 09:10:57.347188 140208979011328 <ipython-input-7-9a70535d1c4a>:82] guid: 3e51261c-fc14-42aa-9f89-fb615b9cee50\n",
      "I1024 09:10:57.347855 140208979011328 <ipython-input-7-9a70535d1c4a>:83] input_ids: 101 1045 2215 2000 2113 2026 4748 8167 3570 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.348480 140208979011328 <ipython-input-7-9a70535d1c4a>:84] attention_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.349154 140208979011328 <ipython-input-7-9a70535d1c4a>:85] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.349719 140208979011328 <ipython-input-7-9a70535d1c4a>:86] label: ask_faq_status_aadhaar (id = 37)\n",
      "I1024 09:10:57.350817 140208979011328 <ipython-input-7-9a70535d1c4a>:81] *** Example ***\n",
      "I1024 09:10:57.351402 140208979011328 <ipython-input-7-9a70535d1c4a>:82] guid: 9717566a-8a7b-4b32-865b-9d920a57b1ef\n",
      "I1024 09:10:57.352041 140208979011328 <ipython-input-7-9a70535d1c4a>:83] input_ids: 101 2129 2064 1045 4638 2026 9779 17516 2906 3570 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.352687 140208979011328 <ipython-input-7-9a70535d1c4a>:84] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.353369 140208979011328 <ipython-input-7-9a70535d1c4a>:85] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.353965 140208979011328 <ipython-input-7-9a70535d1c4a>:86] label: ask_faq_status_aadhaar (id = 37)\n",
      "I1024 09:10:57.355220 140208979011328 <ipython-input-7-9a70535d1c4a>:81] *** Example ***\n",
      "I1024 09:10:57.355961 140208979011328 <ipython-input-7-9a70535d1c4a>:82] guid: 28afb467-4813-4c27-aeb9-bf7e795df33c\n",
      "I1024 09:10:57.356638 140208979011328 <ipython-input-7-9a70535d1c4a>:83] input_ids: 101 2129 2064 1045 3967 9565 2489 9779 17516 2906 3967 2803 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.357347 140208979011328 <ipython-input-7-9a70535d1c4a>:84] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.358010 140208979011328 <ipython-input-7-9a70535d1c4a>:85] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.358649 140208979011328 <ipython-input-7-9a70535d1c4a>:86] label: ask_faq_customercare_aadhaar (id = 38)\n",
      "I1024 09:10:57.359869 140208979011328 <ipython-input-7-9a70535d1c4a>:81] *** Example ***\n",
      "I1024 09:10:57.360543 140208979011328 <ipython-input-7-9a70535d1c4a>:82] guid: 32c79d91-f8df-4d50-bb58-ffdc83a79c9d\n",
      "I1024 09:10:57.361221 140208979011328 <ipython-input-7-9a70535d1c4a>:83] input_ids: 101 26077 1038 16102 11631 2072 1010 9779 25632 2803 6872 3967 2193 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.361928 140208979011328 <ipython-input-7-9a70535d1c4a>:84] attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.362634 140208979011328 <ipython-input-7-9a70535d1c4a>:85] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.363271 140208979011328 <ipython-input-7-9a70535d1c4a>:86] label: ask_faq_customercare_aadhaar (id = 38)\n",
      "I1024 09:10:57.364382 140208979011328 <ipython-input-7-9a70535d1c4a>:81] *** Example ***\n",
      "I1024 09:10:57.365161 140208979011328 <ipython-input-7-9a70535d1c4a>:82] guid: 93d241df-1624-4b49-9523-0c8d3322b4e0\n",
      "I1024 09:10:57.365836 140208979011328 <ipython-input-7-9a70535d1c4a>:83] input_ids: 101 2507 2033 3967 2193 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.366715 140208979011328 <ipython-input-7-9a70535d1c4a>:84] attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.376666 140208979011328 <ipython-input-7-9a70535d1c4a>:85] token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1024 09:10:57.377316 140208979011328 <ipython-input-7-9a70535d1c4a>:86] label: ask_faq_customercare_aadhaar (id = 38)\n",
      "I1024 09:10:57.514966 140208979011328 configuration_utils.py:148] loading configuration file /floyd/home/model/bert-model/checkpoint-1300/config.json\n",
      "I1024 09:10:57.517581 140208979011328 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 97,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1024 09:10:57.518895 140208979011328 modeling_utils.py:334] loading weights file /floyd/home/model/bert-model/checkpoint-1300/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "checkpoint   = os.path.join(args.output_dir, 'checkpoint-1300')\n",
    "tokenizer1    = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
    "eval_dataset = get_examples_dataset(eval_examples, label_list, tokenizer)\n",
    "model1        = model_class.from_pretrained(checkpoint).to(args.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start of evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1024 09:11:11.118481 140208979011328 <ipython-input-12-7408f09bfb68>:82] ***** Running evaluation {} *****\n",
      "I1024 09:11:11.119282 140208979011328 <ipython-input-12-7408f09bfb68>:83]   Num examples = 376\n",
      "I1024 09:11:11.120692 140208979011328 <ipython-input-12-7408f09bfb68>:84]   Batch size = 8\n",
      "Evaluating: 100%|██████████| 47/47 [01:52<00:00,  2.39s/it]\n",
      "I1024 09:13:03.822906 140208979011328 <ipython-input-14-e77f48b92418>:2]  evaluation result = {'acc': 0.625}\n"
     ]
    }
   ],
   "source": [
    "result       = evaluate(args, eval_dataset, model1, tokenizer1)\n",
    "logger.info(\" evaluation result = %s\", result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
